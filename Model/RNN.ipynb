{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-15 02:44:15.759982: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-15 02:44:15.797445: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-15 02:44:15.797480: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-15 02:44:15.797513: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-15 02:44:15.803743: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-15 02:44:15.804590: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-15 02:44:16.730962: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import models, layers\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from pywt import wavedec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>mfcc4</th>\n",
       "      <th>mfcc5</th>\n",
       "      <th>mfcc6</th>\n",
       "      <th>mfcc7</th>\n",
       "      <th>mfcc8</th>\n",
       "      <th>mfcc9</th>\n",
       "      <th>...</th>\n",
       "      <th>cqt52</th>\n",
       "      <th>cqt53</th>\n",
       "      <th>cqt54</th>\n",
       "      <th>cqt55</th>\n",
       "      <th>cqt56</th>\n",
       "      <th>cqt57</th>\n",
       "      <th>cqt58</th>\n",
       "      <th>cqt59</th>\n",
       "      <th>cqt60</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/DWT_NEW/MVP/New_MVP_062.wav</td>\n",
       "      <td>-378.466705</td>\n",
       "      <td>70.777046</td>\n",
       "      <td>-15.043975</td>\n",
       "      <td>-10.483999</td>\n",
       "      <td>-7.787292</td>\n",
       "      <td>-10.019837</td>\n",
       "      <td>-10.438225</td>\n",
       "      <td>-10.765308</td>\n",
       "      <td>-11.529624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004576</td>\n",
       "      <td>0.007013</td>\n",
       "      <td>0.009191</td>\n",
       "      <td>0.009871</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.004856</td>\n",
       "      <td>0.004364</td>\n",
       "      <td>0.004430</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>MVP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/DWT_NEW/MVP/New_MVP_109.wav</td>\n",
       "      <td>-319.873901</td>\n",
       "      <td>86.987167</td>\n",
       "      <td>-4.425532</td>\n",
       "      <td>-24.986303</td>\n",
       "      <td>-16.058350</td>\n",
       "      <td>-17.620874</td>\n",
       "      <td>-21.183941</td>\n",
       "      <td>-13.546381</td>\n",
       "      <td>-13.906720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006113</td>\n",
       "      <td>0.007374</td>\n",
       "      <td>0.003911</td>\n",
       "      <td>0.004396</td>\n",
       "      <td>0.006237</td>\n",
       "      <td>0.002841</td>\n",
       "      <td>0.003259</td>\n",
       "      <td>0.001627</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>MVP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/DWT_NEW/MVP/New_MVP_009.wav</td>\n",
       "      <td>-436.392487</td>\n",
       "      <td>96.536903</td>\n",
       "      <td>15.220769</td>\n",
       "      <td>-3.666383</td>\n",
       "      <td>-7.341067</td>\n",
       "      <td>-16.075756</td>\n",
       "      <td>-19.296213</td>\n",
       "      <td>-12.426279</td>\n",
       "      <td>-12.215953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001060</td>\n",
       "      <td>0.001288</td>\n",
       "      <td>0.002036</td>\n",
       "      <td>0.002741</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>0.002324</td>\n",
       "      <td>0.001372</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.001093</td>\n",
       "      <td>MVP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/DWT_NEW/MVP/New_MVP_177.wav</td>\n",
       "      <td>-260.900574</td>\n",
       "      <td>82.395615</td>\n",
       "      <td>-14.294676</td>\n",
       "      <td>-40.442722</td>\n",
       "      <td>-28.068470</td>\n",
       "      <td>-14.434702</td>\n",
       "      <td>-11.098033</td>\n",
       "      <td>-15.608220</td>\n",
       "      <td>-18.183039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040846</td>\n",
       "      <td>0.037475</td>\n",
       "      <td>0.030191</td>\n",
       "      <td>0.031350</td>\n",
       "      <td>0.024266</td>\n",
       "      <td>0.023387</td>\n",
       "      <td>0.018028</td>\n",
       "      <td>0.016594</td>\n",
       "      <td>0.014518</td>\n",
       "      <td>MVP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/DWT_NEW/MVP/New_MVP_069.wav</td>\n",
       "      <td>-437.852600</td>\n",
       "      <td>95.676224</td>\n",
       "      <td>9.383162</td>\n",
       "      <td>-12.113409</td>\n",
       "      <td>-9.554273</td>\n",
       "      <td>-10.383272</td>\n",
       "      <td>-10.062037</td>\n",
       "      <td>-8.767884</td>\n",
       "      <td>-12.414495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002557</td>\n",
       "      <td>0.003386</td>\n",
       "      <td>0.003017</td>\n",
       "      <td>0.003608</td>\n",
       "      <td>0.003812</td>\n",
       "      <td>0.002936</td>\n",
       "      <td>0.002787</td>\n",
       "      <td>0.003399</td>\n",
       "      <td>0.002704</td>\n",
       "      <td>MVP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              filename       mfcc1      mfcc2      mfcc3  \\\n",
       "0  ../data/DWT_NEW/MVP/New_MVP_062.wav -378.466705  70.777046 -15.043975   \n",
       "1  ../data/DWT_NEW/MVP/New_MVP_109.wav -319.873901  86.987167  -4.425532   \n",
       "2  ../data/DWT_NEW/MVP/New_MVP_009.wav -436.392487  96.536903  15.220769   \n",
       "3  ../data/DWT_NEW/MVP/New_MVP_177.wav -260.900574  82.395615 -14.294676   \n",
       "4  ../data/DWT_NEW/MVP/New_MVP_069.wav -437.852600  95.676224   9.383162   \n",
       "\n",
       "       mfcc4      mfcc5      mfcc6      mfcc7      mfcc8      mfcc9  ...  \\\n",
       "0 -10.483999  -7.787292 -10.019837 -10.438225 -10.765308 -11.529624  ...   \n",
       "1 -24.986303 -16.058350 -17.620874 -21.183941 -13.546381 -13.906720  ...   \n",
       "2  -3.666383  -7.341067 -16.075756 -19.296213 -12.426279 -12.215953  ...   \n",
       "3 -40.442722 -28.068470 -14.434702 -11.098033 -15.608220 -18.183039  ...   \n",
       "4 -12.113409  -9.554273 -10.383272 -10.062037  -8.767884 -12.414495  ...   \n",
       "\n",
       "      cqt52     cqt53     cqt54     cqt55     cqt56     cqt57     cqt58  \\\n",
       "0  0.004576  0.007013  0.009191  0.009871  0.007580  0.004856  0.004364   \n",
       "1  0.006113  0.007374  0.003911  0.004396  0.006237  0.002841  0.003259   \n",
       "2  0.001060  0.001288  0.002036  0.002741  0.003057  0.002324  0.001372   \n",
       "3  0.040846  0.037475  0.030191  0.031350  0.024266  0.023387  0.018028   \n",
       "4  0.002557  0.003386  0.003017  0.003608  0.003812  0.002936  0.002787   \n",
       "\n",
       "      cqt59     cqt60  label  \n",
       "0  0.004430  0.003150    MVP  \n",
       "1  0.001627  0.001817    MVP  \n",
       "2  0.001019  0.001093    MVP  \n",
       "3  0.016594  0.014518    MVP  \n",
       "4  0.003399  0.002704    MVP  \n",
       "\n",
       "[5 rows x 103 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_uri = '../Preprocessing/db1/data_MfccDwtRmsCqtdb1L1.csv'\n",
    "data = pd.read_csv(csv_uri)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 900 entries, 0 to 899\n",
      "Columns: 103 entries, filename to label\n",
      "dtypes: float64(101), object(2)\n",
      "memory usage: 724.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "X = data.drop(['label', 'filename'], axis=1)\n",
    "# X = scaler.fit_transform(X)\n",
    "# X = np.reshape(X, (-1, X.shape[0], X.shape[1], 1))\n",
    "y = data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 101)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    MVP\n",
       "1    MVP\n",
       "2    MVP\n",
       "3    MVP\n",
       "4    MVP\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>mfcc4</th>\n",
       "      <th>mfcc5</th>\n",
       "      <th>mfcc6</th>\n",
       "      <th>mfcc7</th>\n",
       "      <th>mfcc8</th>\n",
       "      <th>mfcc9</th>\n",
       "      <th>mfcc10</th>\n",
       "      <th>...</th>\n",
       "      <th>cqt51</th>\n",
       "      <th>cqt52</th>\n",
       "      <th>cqt53</th>\n",
       "      <th>cqt54</th>\n",
       "      <th>cqt55</th>\n",
       "      <th>cqt56</th>\n",
       "      <th>cqt57</th>\n",
       "      <th>cqt58</th>\n",
       "      <th>cqt59</th>\n",
       "      <th>cqt60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-378.466705</td>\n",
       "      <td>70.777046</td>\n",
       "      <td>-15.043975</td>\n",
       "      <td>-10.483999</td>\n",
       "      <td>-7.787292</td>\n",
       "      <td>-10.019837</td>\n",
       "      <td>-10.438225</td>\n",
       "      <td>-10.765308</td>\n",
       "      <td>-11.529624</td>\n",
       "      <td>-6.286917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003381</td>\n",
       "      <td>0.004576</td>\n",
       "      <td>0.007013</td>\n",
       "      <td>0.009191</td>\n",
       "      <td>0.009871</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.004856</td>\n",
       "      <td>0.004364</td>\n",
       "      <td>0.004430</td>\n",
       "      <td>0.003150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-319.873901</td>\n",
       "      <td>86.987167</td>\n",
       "      <td>-4.425532</td>\n",
       "      <td>-24.986303</td>\n",
       "      <td>-16.058350</td>\n",
       "      <td>-17.620874</td>\n",
       "      <td>-21.183941</td>\n",
       "      <td>-13.546381</td>\n",
       "      <td>-13.906720</td>\n",
       "      <td>-13.717781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007207</td>\n",
       "      <td>0.006113</td>\n",
       "      <td>0.007374</td>\n",
       "      <td>0.003911</td>\n",
       "      <td>0.004396</td>\n",
       "      <td>0.006237</td>\n",
       "      <td>0.002841</td>\n",
       "      <td>0.003259</td>\n",
       "      <td>0.001627</td>\n",
       "      <td>0.001817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-436.392487</td>\n",
       "      <td>96.536903</td>\n",
       "      <td>15.220769</td>\n",
       "      <td>-3.666383</td>\n",
       "      <td>-7.341067</td>\n",
       "      <td>-16.075756</td>\n",
       "      <td>-19.296213</td>\n",
       "      <td>-12.426279</td>\n",
       "      <td>-12.215953</td>\n",
       "      <td>-12.313032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001414</td>\n",
       "      <td>0.001060</td>\n",
       "      <td>0.001288</td>\n",
       "      <td>0.002036</td>\n",
       "      <td>0.002741</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>0.002324</td>\n",
       "      <td>0.001372</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.001093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-260.900574</td>\n",
       "      <td>82.395615</td>\n",
       "      <td>-14.294676</td>\n",
       "      <td>-40.442722</td>\n",
       "      <td>-28.068470</td>\n",
       "      <td>-14.434702</td>\n",
       "      <td>-11.098033</td>\n",
       "      <td>-15.608220</td>\n",
       "      <td>-18.183039</td>\n",
       "      <td>-11.157784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043850</td>\n",
       "      <td>0.040846</td>\n",
       "      <td>0.037475</td>\n",
       "      <td>0.030191</td>\n",
       "      <td>0.031350</td>\n",
       "      <td>0.024266</td>\n",
       "      <td>0.023387</td>\n",
       "      <td>0.018028</td>\n",
       "      <td>0.016594</td>\n",
       "      <td>0.014518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-437.852600</td>\n",
       "      <td>95.676224</td>\n",
       "      <td>9.383162</td>\n",
       "      <td>-12.113409</td>\n",
       "      <td>-9.554273</td>\n",
       "      <td>-10.383272</td>\n",
       "      <td>-10.062037</td>\n",
       "      <td>-8.767884</td>\n",
       "      <td>-12.414495</td>\n",
       "      <td>-6.307548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002647</td>\n",
       "      <td>0.002557</td>\n",
       "      <td>0.003386</td>\n",
       "      <td>0.003017</td>\n",
       "      <td>0.003608</td>\n",
       "      <td>0.003812</td>\n",
       "      <td>0.002936</td>\n",
       "      <td>0.002787</td>\n",
       "      <td>0.003399</td>\n",
       "      <td>0.002704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>-339.158112</td>\n",
       "      <td>40.213173</td>\n",
       "      <td>-36.526974</td>\n",
       "      <td>-53.637939</td>\n",
       "      <td>-18.601725</td>\n",
       "      <td>-12.249957</td>\n",
       "      <td>-10.941161</td>\n",
       "      <td>-9.111422</td>\n",
       "      <td>-10.798549</td>\n",
       "      <td>-5.611834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035250</td>\n",
       "      <td>0.040663</td>\n",
       "      <td>0.033821</td>\n",
       "      <td>0.044480</td>\n",
       "      <td>0.047381</td>\n",
       "      <td>0.049833</td>\n",
       "      <td>0.045619</td>\n",
       "      <td>0.043067</td>\n",
       "      <td>0.030173</td>\n",
       "      <td>0.025898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>-501.082001</td>\n",
       "      <td>89.517166</td>\n",
       "      <td>25.677994</td>\n",
       "      <td>-4.297906</td>\n",
       "      <td>-10.959665</td>\n",
       "      <td>-17.939556</td>\n",
       "      <td>-20.772755</td>\n",
       "      <td>-15.514157</td>\n",
       "      <td>-15.844445</td>\n",
       "      <td>-12.956374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005172</td>\n",
       "      <td>0.003850</td>\n",
       "      <td>0.002997</td>\n",
       "      <td>0.001923</td>\n",
       "      <td>0.001676</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.000971</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>0.000886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>-307.757050</td>\n",
       "      <td>51.899139</td>\n",
       "      <td>-23.147026</td>\n",
       "      <td>-28.208418</td>\n",
       "      <td>-22.437355</td>\n",
       "      <td>-13.074753</td>\n",
       "      <td>-12.573600</td>\n",
       "      <td>-9.405491</td>\n",
       "      <td>-10.770848</td>\n",
       "      <td>-8.731351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032781</td>\n",
       "      <td>0.027149</td>\n",
       "      <td>0.027509</td>\n",
       "      <td>0.045420</td>\n",
       "      <td>0.052697</td>\n",
       "      <td>0.049330</td>\n",
       "      <td>0.044515</td>\n",
       "      <td>0.036902</td>\n",
       "      <td>0.025493</td>\n",
       "      <td>0.022228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>-334.683624</td>\n",
       "      <td>87.311577</td>\n",
       "      <td>6.389525</td>\n",
       "      <td>-1.465219</td>\n",
       "      <td>-13.921110</td>\n",
       "      <td>-18.471697</td>\n",
       "      <td>-14.806891</td>\n",
       "      <td>-16.474894</td>\n",
       "      <td>-18.158365</td>\n",
       "      <td>-17.774797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008435</td>\n",
       "      <td>0.009755</td>\n",
       "      <td>0.009753</td>\n",
       "      <td>0.007868</td>\n",
       "      <td>0.007349</td>\n",
       "      <td>0.005529</td>\n",
       "      <td>0.002896</td>\n",
       "      <td>0.002681</td>\n",
       "      <td>0.003235</td>\n",
       "      <td>0.002716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>-418.720551</td>\n",
       "      <td>96.503845</td>\n",
       "      <td>27.470325</td>\n",
       "      <td>-8.814580</td>\n",
       "      <td>-17.037363</td>\n",
       "      <td>-22.108522</td>\n",
       "      <td>-18.823912</td>\n",
       "      <td>-15.362716</td>\n",
       "      <td>-20.845629</td>\n",
       "      <td>-21.286650</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005636</td>\n",
       "      <td>0.005060</td>\n",
       "      <td>0.007039</td>\n",
       "      <td>0.007178</td>\n",
       "      <td>0.005058</td>\n",
       "      <td>0.003336</td>\n",
       "      <td>0.002948</td>\n",
       "      <td>0.001577</td>\n",
       "      <td>0.001265</td>\n",
       "      <td>0.001357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          mfcc1      mfcc2      mfcc3      mfcc4      mfcc5      mfcc6  \\\n",
       "0   -378.466705  70.777046 -15.043975 -10.483999  -7.787292 -10.019837   \n",
       "1   -319.873901  86.987167  -4.425532 -24.986303 -16.058350 -17.620874   \n",
       "2   -436.392487  96.536903  15.220769  -3.666383  -7.341067 -16.075756   \n",
       "3   -260.900574  82.395615 -14.294676 -40.442722 -28.068470 -14.434702   \n",
       "4   -437.852600  95.676224   9.383162 -12.113409  -9.554273 -10.383272   \n",
       "..          ...        ...        ...        ...        ...        ...   \n",
       "895 -339.158112  40.213173 -36.526974 -53.637939 -18.601725 -12.249957   \n",
       "896 -501.082001  89.517166  25.677994  -4.297906 -10.959665 -17.939556   \n",
       "897 -307.757050  51.899139 -23.147026 -28.208418 -22.437355 -13.074753   \n",
       "898 -334.683624  87.311577   6.389525  -1.465219 -13.921110 -18.471697   \n",
       "899 -418.720551  96.503845  27.470325  -8.814580 -17.037363 -22.108522   \n",
       "\n",
       "         mfcc7      mfcc8      mfcc9     mfcc10  ...     cqt51     cqt52  \\\n",
       "0   -10.438225 -10.765308 -11.529624  -6.286917  ...  0.003381  0.004576   \n",
       "1   -21.183941 -13.546381 -13.906720 -13.717781  ...  0.007207  0.006113   \n",
       "2   -19.296213 -12.426279 -12.215953 -12.313032  ...  0.001414  0.001060   \n",
       "3   -11.098033 -15.608220 -18.183039 -11.157784  ...  0.043850  0.040846   \n",
       "4   -10.062037  -8.767884 -12.414495  -6.307548  ...  0.002647  0.002557   \n",
       "..         ...        ...        ...        ...  ...       ...       ...   \n",
       "895 -10.941161  -9.111422 -10.798549  -5.611834  ...  0.035250  0.040663   \n",
       "896 -20.772755 -15.514157 -15.844445 -12.956374  ...  0.005172  0.003850   \n",
       "897 -12.573600  -9.405491 -10.770848  -8.731351  ...  0.032781  0.027149   \n",
       "898 -14.806891 -16.474894 -18.158365 -17.774797  ...  0.008435  0.009755   \n",
       "899 -18.823912 -15.362716 -20.845629 -21.286650  ...  0.005636  0.005060   \n",
       "\n",
       "        cqt53     cqt54     cqt55     cqt56     cqt57     cqt58     cqt59  \\\n",
       "0    0.007013  0.009191  0.009871  0.007580  0.004856  0.004364  0.004430   \n",
       "1    0.007374  0.003911  0.004396  0.006237  0.002841  0.003259  0.001627   \n",
       "2    0.001288  0.002036  0.002741  0.003057  0.002324  0.001372  0.001019   \n",
       "3    0.037475  0.030191  0.031350  0.024266  0.023387  0.018028  0.016594   \n",
       "4    0.003386  0.003017  0.003608  0.003812  0.002936  0.002787  0.003399   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "895  0.033821  0.044480  0.047381  0.049833  0.045619  0.043067  0.030173   \n",
       "896  0.002997  0.001923  0.001676  0.001316  0.000971  0.000981  0.001023   \n",
       "897  0.027509  0.045420  0.052697  0.049330  0.044515  0.036902  0.025493   \n",
       "898  0.009753  0.007868  0.007349  0.005529  0.002896  0.002681  0.003235   \n",
       "899  0.007039  0.007178  0.005058  0.003336  0.002948  0.001577  0.001265   \n",
       "\n",
       "        cqt60  \n",
       "0    0.003150  \n",
       "1    0.001817  \n",
       "2    0.001093  \n",
       "3    0.014518  \n",
       "4    0.002704  \n",
       "..        ...  \n",
       "895  0.025898  \n",
       "896  0.000886  \n",
       "897  0.022228  \n",
       "898  0.002716  \n",
       "899  0.001357  \n",
       "\n",
       "[900 rows x 101 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 101)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>mfcc4</th>\n",
       "      <th>mfcc5</th>\n",
       "      <th>mfcc6</th>\n",
       "      <th>mfcc7</th>\n",
       "      <th>mfcc8</th>\n",
       "      <th>mfcc9</th>\n",
       "      <th>mfcc10</th>\n",
       "      <th>...</th>\n",
       "      <th>cqt51</th>\n",
       "      <th>cqt52</th>\n",
       "      <th>cqt53</th>\n",
       "      <th>cqt54</th>\n",
       "      <th>cqt55</th>\n",
       "      <th>cqt56</th>\n",
       "      <th>cqt57</th>\n",
       "      <th>cqt58</th>\n",
       "      <th>cqt59</th>\n",
       "      <th>cqt60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-385.906982</td>\n",
       "      <td>74.895340</td>\n",
       "      <td>39.821186</td>\n",
       "      <td>-8.971136</td>\n",
       "      <td>-22.192118</td>\n",
       "      <td>-25.015581</td>\n",
       "      <td>-27.064453</td>\n",
       "      <td>-24.045132</td>\n",
       "      <td>-27.759182</td>\n",
       "      <td>-29.726229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002294</td>\n",
       "      <td>0.001526</td>\n",
       "      <td>0.002158</td>\n",
       "      <td>0.002329</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.001506</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.000770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>-415.968506</td>\n",
       "      <td>107.517372</td>\n",
       "      <td>44.947140</td>\n",
       "      <td>-2.356348</td>\n",
       "      <td>-16.818644</td>\n",
       "      <td>-22.711168</td>\n",
       "      <td>-24.376642</td>\n",
       "      <td>-19.630342</td>\n",
       "      <td>-19.142199</td>\n",
       "      <td>-15.471057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003029</td>\n",
       "      <td>0.002132</td>\n",
       "      <td>0.001797</td>\n",
       "      <td>0.001642</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.001127</td>\n",
       "      <td>0.000976</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>0.000717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>-427.811066</td>\n",
       "      <td>102.884872</td>\n",
       "      <td>46.127216</td>\n",
       "      <td>6.943640</td>\n",
       "      <td>-10.577306</td>\n",
       "      <td>-21.495943</td>\n",
       "      <td>-30.066357</td>\n",
       "      <td>-20.540812</td>\n",
       "      <td>-12.175126</td>\n",
       "      <td>-10.055816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004527</td>\n",
       "      <td>0.003815</td>\n",
       "      <td>0.002654</td>\n",
       "      <td>0.001473</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.000984</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.000361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>-358.147736</td>\n",
       "      <td>95.750092</td>\n",
       "      <td>-6.823721</td>\n",
       "      <td>-38.393955</td>\n",
       "      <td>-33.172913</td>\n",
       "      <td>-28.448936</td>\n",
       "      <td>-25.357052</td>\n",
       "      <td>-24.172688</td>\n",
       "      <td>-21.519249</td>\n",
       "      <td>-16.292105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.014028</td>\n",
       "      <td>0.014584</td>\n",
       "      <td>0.016448</td>\n",
       "      <td>0.011797</td>\n",
       "      <td>0.013386</td>\n",
       "      <td>0.011898</td>\n",
       "      <td>0.007499</td>\n",
       "      <td>0.006875</td>\n",
       "      <td>0.006322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>-427.476135</td>\n",
       "      <td>98.611679</td>\n",
       "      <td>36.363655</td>\n",
       "      <td>-0.854163</td>\n",
       "      <td>-14.472300</td>\n",
       "      <td>-24.841476</td>\n",
       "      <td>-19.455835</td>\n",
       "      <td>-19.234936</td>\n",
       "      <td>-19.875013</td>\n",
       "      <td>-20.455000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002225</td>\n",
       "      <td>0.001244</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.001335</td>\n",
       "      <td>0.001256</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>0.001312</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>0.000961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>-397.429016</td>\n",
       "      <td>77.593384</td>\n",
       "      <td>24.298113</td>\n",
       "      <td>-15.595834</td>\n",
       "      <td>-26.727154</td>\n",
       "      <td>-24.668875</td>\n",
       "      <td>-24.234287</td>\n",
       "      <td>-23.968037</td>\n",
       "      <td>-30.278244</td>\n",
       "      <td>-33.223251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004297</td>\n",
       "      <td>0.004133</td>\n",
       "      <td>0.005123</td>\n",
       "      <td>0.007229</td>\n",
       "      <td>0.008914</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>0.005154</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>0.001324</td>\n",
       "      <td>0.000832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>-410.292542</td>\n",
       "      <td>98.300247</td>\n",
       "      <td>44.424370</td>\n",
       "      <td>5.566563</td>\n",
       "      <td>-9.317470</td>\n",
       "      <td>-21.559860</td>\n",
       "      <td>-24.616989</td>\n",
       "      <td>-15.818483</td>\n",
       "      <td>-16.259008</td>\n",
       "      <td>-13.159559</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003473</td>\n",
       "      <td>0.003598</td>\n",
       "      <td>0.002932</td>\n",
       "      <td>0.001842</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>0.000991</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.001271</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.000585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>-408.968292</td>\n",
       "      <td>94.780281</td>\n",
       "      <td>24.131092</td>\n",
       "      <td>-8.054283</td>\n",
       "      <td>-17.265577</td>\n",
       "      <td>-19.051916</td>\n",
       "      <td>-18.081953</td>\n",
       "      <td>-19.145655</td>\n",
       "      <td>-21.355644</td>\n",
       "      <td>-19.833616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006677</td>\n",
       "      <td>0.006362</td>\n",
       "      <td>0.006968</td>\n",
       "      <td>0.005794</td>\n",
       "      <td>0.005023</td>\n",
       "      <td>0.004618</td>\n",
       "      <td>0.003270</td>\n",
       "      <td>0.002189</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.001347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>-383.255219</td>\n",
       "      <td>73.887856</td>\n",
       "      <td>3.322746</td>\n",
       "      <td>-1.166246</td>\n",
       "      <td>-1.575055</td>\n",
       "      <td>-1.824785</td>\n",
       "      <td>-8.054250</td>\n",
       "      <td>-10.752819</td>\n",
       "      <td>-6.060513</td>\n",
       "      <td>-11.980646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001899</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>0.001212</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>0.003594</td>\n",
       "      <td>0.004990</td>\n",
       "      <td>0.003905</td>\n",
       "      <td>0.001831</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>0.001580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>-460.462677</td>\n",
       "      <td>89.227898</td>\n",
       "      <td>14.550024</td>\n",
       "      <td>-11.596138</td>\n",
       "      <td>-7.281045</td>\n",
       "      <td>-10.601804</td>\n",
       "      <td>-14.203653</td>\n",
       "      <td>-7.776899</td>\n",
       "      <td>-7.740396</td>\n",
       "      <td>-6.839746</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001712</td>\n",
       "      <td>0.002078</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.002810</td>\n",
       "      <td>0.002731</td>\n",
       "      <td>0.003004</td>\n",
       "      <td>0.002710</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>0.001914</td>\n",
       "      <td>0.001321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>720 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          mfcc1       mfcc2      mfcc3      mfcc4      mfcc5      mfcc6  \\\n",
       "10  -385.906982   74.895340  39.821186  -8.971136 -22.192118 -25.015581   \n",
       "334 -415.968506  107.517372  44.947140  -2.356348 -16.818644 -22.711168   \n",
       "244 -427.811066  102.884872  46.127216   6.943640 -10.577306 -21.495943   \n",
       "678 -358.147736   95.750092  -6.823721 -38.393955 -33.172913 -28.448936   \n",
       "306 -427.476135   98.611679  36.363655  -0.854163 -14.472300 -24.841476   \n",
       "..          ...         ...        ...        ...        ...        ...   \n",
       "106 -397.429016   77.593384  24.298113 -15.595834 -26.727154 -24.668875   \n",
       "270 -410.292542   98.300247  44.424370   5.566563  -9.317470 -21.559860   \n",
       "860 -408.968292   94.780281  24.131092  -8.054283 -17.265577 -19.051916   \n",
       "435 -383.255219   73.887856   3.322746  -1.166246  -1.575055  -1.824785   \n",
       "102 -460.462677   89.227898  14.550024 -11.596138  -7.281045 -10.601804   \n",
       "\n",
       "         mfcc7      mfcc8      mfcc9     mfcc10  ...     cqt51     cqt52  \\\n",
       "10  -27.064453 -24.045132 -27.759182 -29.726229  ...  0.002294  0.001526   \n",
       "334 -24.376642 -19.630342 -19.142199 -15.471057  ...  0.003029  0.002132   \n",
       "244 -30.066357 -20.540812 -12.175126 -10.055816  ...  0.004527  0.003815   \n",
       "678 -25.357052 -24.172688 -21.519249 -16.292105  ...  0.014000  0.014028   \n",
       "306 -19.455835 -19.234936 -19.875013 -20.455000  ...  0.002225  0.001244   \n",
       "..         ...        ...        ...        ...  ...       ...       ...   \n",
       "106 -24.234287 -23.968037 -30.278244 -33.223251  ...  0.004297  0.004133   \n",
       "270 -24.616989 -15.818483 -16.259008 -13.159559  ...  0.003473  0.003598   \n",
       "860 -18.081953 -19.145655 -21.355644 -19.833616  ...  0.006677  0.006362   \n",
       "435  -8.054250 -10.752819  -6.060513 -11.980646  ...  0.001899  0.001540   \n",
       "102 -14.203653  -7.776899  -7.740396  -6.839746  ...  0.001712  0.002078   \n",
       "\n",
       "        cqt53     cqt54     cqt55     cqt56     cqt57     cqt58     cqt59  \\\n",
       "10   0.002158  0.002329  0.002317  0.001506  0.001128  0.000906  0.000822   \n",
       "334  0.001797  0.001642  0.001062  0.001127  0.000976  0.000559  0.000708   \n",
       "244  0.002654  0.001473  0.000573  0.000913  0.000984  0.000708  0.000538   \n",
       "678  0.014584  0.016448  0.011797  0.013386  0.011898  0.007499  0.006875   \n",
       "306  0.001890  0.001335  0.001256  0.001930  0.001312  0.000906  0.001056   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "106  0.005123  0.007229  0.008914  0.008600  0.005154  0.001585  0.001324   \n",
       "270  0.002932  0.001842  0.001216  0.000991  0.001201  0.001271  0.000916   \n",
       "860  0.006968  0.005794  0.005023  0.004618  0.003270  0.002189  0.001938   \n",
       "435  0.001212  0.001930  0.003594  0.004990  0.003905  0.001831  0.001534   \n",
       "102  0.002631  0.002810  0.002731  0.003004  0.002710  0.002108  0.001914   \n",
       "\n",
       "        cqt60  \n",
       "10   0.000770  \n",
       "334  0.000717  \n",
       "244  0.000361  \n",
       "678  0.006322  \n",
       "306  0.000961  \n",
       "..        ...  \n",
       "106  0.000832  \n",
       "270  0.000585  \n",
       "860  0.001347  \n",
       "435  0.001580  \n",
       "102  0.001321  \n",
       "\n",
       "[720 rows x 101 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180,)\n",
      "(720, 101, 1)\n",
      "(180, 101, 1)\n"
     ]
    }
   ],
   "source": [
    "lb = LabelEncoder()\n",
    "X_train = np.expand_dims(X_train, axis=2)\n",
    "X_test = np.expand_dims(X_test, axis=2)\n",
    "print(y_test.shape)\n",
    "y_test = tf.keras.utils.to_categorical(lb.fit_transform(y_test))\n",
    "y_train = tf.keras.utils.to_categorical(lb.fit_transform(y_train))\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make RNN model\n",
    "def build_model():\n",
    "    model = models.Sequential(\n",
    "        [\n",
    "            layers.SimpleRNN(64,activation='tanh',input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True),\n",
    "            \n",
    "            layers.Flatten(),\n",
    "            layers.Dense(64, activation=\"relu\"),\n",
    "            layers.Dense(32, activation=\"relu\"),\n",
    "\n",
    "            layers.BatchNormalization(),\n",
    "\n",
    "            layers.Dense(5, activation=\"softmax\"),\n",
    "            # layers.SimpleRNN(64,activation='tanh',input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True),\n",
    "\n",
    "            # layers.Flatten(),\n",
    "            # layers.Dense(64, activation=\"relu\", activity_regularizer=tf.keras.regularizers.l2(1e-4)),\n",
    "            # layers.Dense(32, activation=\"relu\", activity_regularizer=tf.keras.regularizers.l2(1e-4)),\n",
    "\n",
    "            # layers.BatchNormalization(),\n",
    "\n",
    "            # layers.Dense(5, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 101, 64)           4224      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6464)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                413760    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 32)                128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 420357 (1.60 MB)\n",
      "Trainable params: 420293 (1.60 MB)\n",
      "Non-trainable params: 64 (256.00 Byte)\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rafli/anaconda3/envs/tf/lib/python3.11/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()\n",
    "model_uri = '../modelh5/model_rnn_tuning.h5'\n",
    "model.save('../modelh5/model_rnn_tuning.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 2s 24ms/step - loss: 1.0131 - acc: 0.6347 - val_loss: 1.1572 - val_acc: 0.7667\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.5244 - acc: 0.8458 - val_loss: 1.0204 - val_acc: 0.6611\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.4152 - acc: 0.8792 - val_loss: 0.9599 - val_acc: 0.7333\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.3465 - acc: 0.9083 - val_loss: 0.8062 - val_acc: 0.8444\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.2874 - acc: 0.9542 - val_loss: 0.6980 - val_acc: 0.9111\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.2472 - acc: 0.9667 - val_loss: 0.6338 - val_acc: 0.9333\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.2053 - acc: 0.9792 - val_loss: 0.5743 - val_acc: 0.9611\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.1785 - acc: 0.9806 - val_loss: 0.4783 - val_acc: 0.9667\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.1636 - acc: 0.9917 - val_loss: 0.4372 - val_acc: 0.9556\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.1478 - acc: 0.9931 - val_loss: 0.4065 - val_acc: 0.9722\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.1340 - acc: 0.9944 - val_loss: 0.3697 - val_acc: 0.9611\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.1229 - acc: 0.9944 - val_loss: 0.3221 - val_acc: 0.9500\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.1051 - acc: 0.9972 - val_loss: 0.2755 - val_acc: 0.9722\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0976 - acc: 0.9986 - val_loss: 0.2415 - val_acc: 0.9833\n",
      "Epoch 15/50\n",
      " 1/23 [>.............................] - ETA: 0s - loss: 0.1708 - acc: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/rafli/Documents/TA/vhd-machine-learning/Model/RNN.ipynb Cell 16\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rafli/Documents/TA/vhd-machine-learning/Model/RNN.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m optimazer \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.0001\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rafli/Documents/TA/vhd-machine-learning/Model/RNN.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39moptimazer, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39macc\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/rafli/Documents/TA/vhd-machine-learning/Model/RNN.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(X_test, y_test))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rafli/Documents/TA/vhd-machine-learning/Model/RNN.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# history = model.fit(X_train, y_train, epochs=35, batch_size=16, validation_data=(X_test, y_test))\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1784\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    868\u001b[0m       args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_config\n\u001b[1;32m    869\u001b[0m   )\n\u001b[1;32m    870\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mflat_call(args)\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_call\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    218\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    253\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    254\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    255\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    257\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1480\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1481\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1482\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1483\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1484\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1485\u001b[0m   )\n\u001b[1;32m   1486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimazer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimazer, loss='categorical_crossentropy', metrics=['acc'])\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
    "# history = model.fit(X_train, y_train, epochs=35, batch_size=16, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0492 - acc: 0.9889\n",
      "Accuracy on test set is: 0.9888888597488403\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate model on test set\n",
    "test_error, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Accuracy on test set is: {}\".format(test_accuracy))\n",
    "\n",
    "\n",
    "# plot accuracy/error for training and validation\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(history.history['acc'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_acc'], label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[35,  0,  0,  0,  0],\n",
       "       [ 1, 29,  1,  0,  0],\n",
       "       [ 0,  0, 38,  0,  0],\n",
       "       [ 0,  0,  0, 35,  0],\n",
       "       [ 0,  0,  0,  0, 41]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = model.predict(X_test)\n",
    "y_p = np.argmax(y_pred, axis=1)\n",
    "y_t = np.argmax(y_test, axis=1)\n",
    "cm = confusion_matrix(y_t, y_p)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        35\n",
      "           1       1.00      0.94      0.97        31\n",
      "           2       0.97      1.00      0.99        38\n",
      "           3       1.00      1.00      1.00        35\n",
      "           4       1.00      1.00      1.00        41\n",
      "\n",
      "    accuracy                           0.99       180\n",
      "   macro avg       0.99      0.99      0.99       180\n",
      "weighted avg       0.99      0.99      0.99       180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_t, y_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 101, 64)           4224      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6464)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                413760    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 32)                128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 420357 (1.60 MB)\n",
      "Trainable params: 420293 (1.60 MB)\n",
      "Non-trainable params: 64 (256.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model(model_uri)\n",
    "new_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "import json\n",
    "header = 'filename'\n",
    "for i in range(1, 41):\n",
    "    header += f' mfcc{i}'\n",
    "header += ' rms'\n",
    "for i in range(1, 61):\n",
    "  header += f' cqt{i}'\n",
    "header += ' label'\n",
    "header = header.split()\n",
    "\n",
    "\n",
    "def extract_mfcc(audiofile):\n",
    "    file = open('test.csv', 'w', newline='')\n",
    "    with file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(header)\n",
    "    y, sr = librosa.load(audiofile, mono=True, duration=3, sr=8000)\n",
    "    coeffs = wavedec(y, 'db1', level=10)\n",
    "    cA,cD10,cD9,cD8,cD7,cD6,cD5,cD4,cD3,cD2, cD1 = coeffs\n",
    "    mfcc = librosa.feature.mfcc(y=cD1, sr=8000, n_mfcc=40, n_fft=2048, hop_length=512, n_mels=128)\n",
    "    rms = librosa.feature.rms(y=cD1)[0]\n",
    "    cqt = np.abs(librosa.cqt(y=cD1, sr=sr, n_bins=60)) \n",
    "    combined_features = np.concatenate((mfcc, rms.reshape(1, -1), cqt), axis=0)\n",
    "    to_append = f'Signal'\n",
    "    for e in combined_features:\n",
    "        to_append += f' {np.mean(e.T, axis=0)}'\n",
    "    file = open('test.csv', 'a', newline='')\n",
    "    with file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(to_append.split())\n",
    "\n",
    "def predict(audio):\n",
    "    model = tf.keras.models.load_model(model_uri)\n",
    "    extract_mfcc(audio)\n",
    "    data = pd.read_csv('test.csv')\n",
    "    df = data.drop(['label', 'filename'], axis=1)\n",
    "    pred = model.predict(df)\n",
    "    class_labels = ['AS', 'MR', 'MS', 'MVP', 'N']\n",
    "    cek = np.argmax(pred[0])\n",
    "    print(pred[0])\n",
    "    print(cek)\n",
    "    print(f'Predicted class: {class_labels[cek]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 158ms/step\n",
      "[3.6176993e-04 8.4560056e-04 4.8873026e-04 2.8812847e-04 9.9801576e-01]\n",
      "4\n",
      "Predicted class: N\n"
     ]
    }
   ],
   "source": [
    "predict('../data/training/N/New_N_003.wav')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

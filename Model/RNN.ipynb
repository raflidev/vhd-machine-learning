{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import models, layers\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from pywt import wavedec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>mfcc4</th>\n",
       "      <th>mfcc5</th>\n",
       "      <th>mfcc6</th>\n",
       "      <th>mfcc7</th>\n",
       "      <th>mfcc8</th>\n",
       "      <th>mfcc9</th>\n",
       "      <th>...</th>\n",
       "      <th>cqt52</th>\n",
       "      <th>cqt53</th>\n",
       "      <th>cqt54</th>\n",
       "      <th>cqt55</th>\n",
       "      <th>cqt56</th>\n",
       "      <th>cqt57</th>\n",
       "      <th>cqt58</th>\n",
       "      <th>cqt59</th>\n",
       "      <th>cqt60</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/DWT_NEW/MVP/New_MVP_062.wav</td>\n",
       "      <td>88.547943</td>\n",
       "      <td>-34.731178</td>\n",
       "      <td>17.439774</td>\n",
       "      <td>3.966827</td>\n",
       "      <td>-17.346939</td>\n",
       "      <td>18.881588</td>\n",
       "      <td>-17.580509</td>\n",
       "      <td>8.225138</td>\n",
       "      <td>2.163004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162481</td>\n",
       "      <td>0.128590</td>\n",
       "      <td>0.253865</td>\n",
       "      <td>0.286246</td>\n",
       "      <td>0.232347</td>\n",
       "      <td>0.166034</td>\n",
       "      <td>0.149659</td>\n",
       "      <td>0.175466</td>\n",
       "      <td>0.264108</td>\n",
       "      <td>MVP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/DWT_NEW/MVP/New_MVP_109.wav</td>\n",
       "      <td>130.248093</td>\n",
       "      <td>-18.175362</td>\n",
       "      <td>-7.527256</td>\n",
       "      <td>-1.821126</td>\n",
       "      <td>-0.783999</td>\n",
       "      <td>9.139212</td>\n",
       "      <td>-30.255112</td>\n",
       "      <td>-18.019503</td>\n",
       "      <td>-3.269579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.272742</td>\n",
       "      <td>0.214996</td>\n",
       "      <td>0.163759</td>\n",
       "      <td>0.185034</td>\n",
       "      <td>0.284470</td>\n",
       "      <td>0.427768</td>\n",
       "      <td>0.583855</td>\n",
       "      <td>0.714654</td>\n",
       "      <td>0.804361</td>\n",
       "      <td>MVP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/DWT_NEW/MVP/New_MVP_009.wav</td>\n",
       "      <td>68.611404</td>\n",
       "      <td>-30.707958</td>\n",
       "      <td>43.091286</td>\n",
       "      <td>-5.395578</td>\n",
       "      <td>-31.639091</td>\n",
       "      <td>25.854515</td>\n",
       "      <td>-19.372128</td>\n",
       "      <td>12.241970</td>\n",
       "      <td>-3.681171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.268128</td>\n",
       "      <td>0.329467</td>\n",
       "      <td>0.240955</td>\n",
       "      <td>0.215759</td>\n",
       "      <td>0.290983</td>\n",
       "      <td>0.327005</td>\n",
       "      <td>0.241768</td>\n",
       "      <td>0.163038</td>\n",
       "      <td>0.190981</td>\n",
       "      <td>MVP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/DWT_NEW/MVP/New_MVP_177.wav</td>\n",
       "      <td>124.010841</td>\n",
       "      <td>-26.582684</td>\n",
       "      <td>4.632347</td>\n",
       "      <td>-2.877658</td>\n",
       "      <td>-2.610994</td>\n",
       "      <td>1.804899</td>\n",
       "      <td>-2.408908</td>\n",
       "      <td>5.523919</td>\n",
       "      <td>-0.094534</td>\n",
       "      <td>...</td>\n",
       "      <td>0.535192</td>\n",
       "      <td>0.555842</td>\n",
       "      <td>0.328036</td>\n",
       "      <td>0.101016</td>\n",
       "      <td>0.362609</td>\n",
       "      <td>0.401901</td>\n",
       "      <td>0.259996</td>\n",
       "      <td>0.146674</td>\n",
       "      <td>0.301535</td>\n",
       "      <td>MVP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/DWT_NEW/MVP/New_MVP_069.wav</td>\n",
       "      <td>87.647217</td>\n",
       "      <td>-33.906952</td>\n",
       "      <td>0.952698</td>\n",
       "      <td>-12.743137</td>\n",
       "      <td>-30.600828</td>\n",
       "      <td>29.831501</td>\n",
       "      <td>-26.453606</td>\n",
       "      <td>7.694873</td>\n",
       "      <td>0.659293</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448852</td>\n",
       "      <td>0.387767</td>\n",
       "      <td>0.466638</td>\n",
       "      <td>0.528683</td>\n",
       "      <td>0.326940</td>\n",
       "      <td>0.347330</td>\n",
       "      <td>0.452033</td>\n",
       "      <td>0.500666</td>\n",
       "      <td>0.408247</td>\n",
       "      <td>MVP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              filename       mfcc1      mfcc2      mfcc3  \\\n",
       "0  ../data/DWT_NEW/MVP/New_MVP_062.wav   88.547943 -34.731178  17.439774   \n",
       "1  ../data/DWT_NEW/MVP/New_MVP_109.wav  130.248093 -18.175362  -7.527256   \n",
       "2  ../data/DWT_NEW/MVP/New_MVP_009.wav   68.611404 -30.707958  43.091286   \n",
       "3  ../data/DWT_NEW/MVP/New_MVP_177.wav  124.010841 -26.582684   4.632347   \n",
       "4  ../data/DWT_NEW/MVP/New_MVP_069.wav   87.647217 -33.906952   0.952698   \n",
       "\n",
       "       mfcc4      mfcc5      mfcc6      mfcc7      mfcc8     mfcc9  ...  \\\n",
       "0   3.966827 -17.346939  18.881588 -17.580509   8.225138  2.163004  ...   \n",
       "1  -1.821126  -0.783999   9.139212 -30.255112 -18.019503 -3.269579  ...   \n",
       "2  -5.395578 -31.639091  25.854515 -19.372128  12.241970 -3.681171  ...   \n",
       "3  -2.877658  -2.610994   1.804899  -2.408908   5.523919 -0.094534  ...   \n",
       "4 -12.743137 -30.600828  29.831501 -26.453606   7.694873  0.659293  ...   \n",
       "\n",
       "      cqt52     cqt53     cqt54     cqt55     cqt56     cqt57     cqt58  \\\n",
       "0  0.162481  0.128590  0.253865  0.286246  0.232347  0.166034  0.149659   \n",
       "1  0.272742  0.214996  0.163759  0.185034  0.284470  0.427768  0.583855   \n",
       "2  0.268128  0.329467  0.240955  0.215759  0.290983  0.327005  0.241768   \n",
       "3  0.535192  0.555842  0.328036  0.101016  0.362609  0.401901  0.259996   \n",
       "4  0.448852  0.387767  0.466638  0.528683  0.326940  0.347330  0.452033   \n",
       "\n",
       "      cqt59     cqt60  label  \n",
       "0  0.175466  0.264108    MVP  \n",
       "1  0.714654  0.804361    MVP  \n",
       "2  0.163038  0.190981    MVP  \n",
       "3  0.146674  0.301535    MVP  \n",
       "4  0.500666  0.408247    MVP  \n",
       "\n",
       "[5 rows x 103 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_uri = '../Preprocessing/db1/data_MfccDwtRmsCqtdb1L5.csv'\n",
    "data = pd.read_csv(csv_uri)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 900 entries, 0 to 899\n",
      "Columns: 103 entries, filename to label\n",
      "dtypes: float64(101), object(2)\n",
      "memory usage: 724.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "X = data.drop(['label', 'filename'], axis=1)\n",
    "# X = scaler.fit_transform(X)\n",
    "# X = np.reshape(X, (-1, X.shape[0], X.shape[1], 1))\n",
    "y = data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 101)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    MVP\n",
       "1    MVP\n",
       "2    MVP\n",
       "3    MVP\n",
       "4    MVP\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>mfcc4</th>\n",
       "      <th>mfcc5</th>\n",
       "      <th>mfcc6</th>\n",
       "      <th>mfcc7</th>\n",
       "      <th>mfcc8</th>\n",
       "      <th>mfcc9</th>\n",
       "      <th>mfcc10</th>\n",
       "      <th>...</th>\n",
       "      <th>cqt51</th>\n",
       "      <th>cqt52</th>\n",
       "      <th>cqt53</th>\n",
       "      <th>cqt54</th>\n",
       "      <th>cqt55</th>\n",
       "      <th>cqt56</th>\n",
       "      <th>cqt57</th>\n",
       "      <th>cqt58</th>\n",
       "      <th>cqt59</th>\n",
       "      <th>cqt60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.547943</td>\n",
       "      <td>-34.731178</td>\n",
       "      <td>17.439774</td>\n",
       "      <td>3.966827</td>\n",
       "      <td>-17.346939</td>\n",
       "      <td>18.881588</td>\n",
       "      <td>-17.580509</td>\n",
       "      <td>8.225138</td>\n",
       "      <td>2.163004</td>\n",
       "      <td>-6.991869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080291</td>\n",
       "      <td>0.162481</td>\n",
       "      <td>0.128590</td>\n",
       "      <td>0.253865</td>\n",
       "      <td>0.286246</td>\n",
       "      <td>0.232347</td>\n",
       "      <td>0.166034</td>\n",
       "      <td>0.149659</td>\n",
       "      <td>0.175466</td>\n",
       "      <td>0.264108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>130.248093</td>\n",
       "      <td>-18.175362</td>\n",
       "      <td>-7.527256</td>\n",
       "      <td>-1.821126</td>\n",
       "      <td>-0.783999</td>\n",
       "      <td>9.139212</td>\n",
       "      <td>-30.255112</td>\n",
       "      <td>-18.019503</td>\n",
       "      <td>-3.269579</td>\n",
       "      <td>6.034618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.317061</td>\n",
       "      <td>0.272742</td>\n",
       "      <td>0.214996</td>\n",
       "      <td>0.163759</td>\n",
       "      <td>0.185034</td>\n",
       "      <td>0.284470</td>\n",
       "      <td>0.427768</td>\n",
       "      <td>0.583855</td>\n",
       "      <td>0.714654</td>\n",
       "      <td>0.804361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68.611404</td>\n",
       "      <td>-30.707958</td>\n",
       "      <td>43.091286</td>\n",
       "      <td>-5.395578</td>\n",
       "      <td>-31.639091</td>\n",
       "      <td>25.854515</td>\n",
       "      <td>-19.372128</td>\n",
       "      <td>12.241970</td>\n",
       "      <td>-3.681171</td>\n",
       "      <td>-0.359709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.276001</td>\n",
       "      <td>0.268128</td>\n",
       "      <td>0.329467</td>\n",
       "      <td>0.240955</td>\n",
       "      <td>0.215759</td>\n",
       "      <td>0.290983</td>\n",
       "      <td>0.327005</td>\n",
       "      <td>0.241768</td>\n",
       "      <td>0.163038</td>\n",
       "      <td>0.190981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>124.010841</td>\n",
       "      <td>-26.582684</td>\n",
       "      <td>4.632347</td>\n",
       "      <td>-2.877658</td>\n",
       "      <td>-2.610994</td>\n",
       "      <td>1.804899</td>\n",
       "      <td>-2.408908</td>\n",
       "      <td>5.523919</td>\n",
       "      <td>-0.094534</td>\n",
       "      <td>6.949768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438422</td>\n",
       "      <td>0.535192</td>\n",
       "      <td>0.555842</td>\n",
       "      <td>0.328036</td>\n",
       "      <td>0.101016</td>\n",
       "      <td>0.362609</td>\n",
       "      <td>0.401901</td>\n",
       "      <td>0.259996</td>\n",
       "      <td>0.146674</td>\n",
       "      <td>0.301535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.647217</td>\n",
       "      <td>-33.906952</td>\n",
       "      <td>0.952698</td>\n",
       "      <td>-12.743137</td>\n",
       "      <td>-30.600828</td>\n",
       "      <td>29.831501</td>\n",
       "      <td>-26.453606</td>\n",
       "      <td>7.694873</td>\n",
       "      <td>0.659293</td>\n",
       "      <td>-6.993608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261029</td>\n",
       "      <td>0.448852</td>\n",
       "      <td>0.387767</td>\n",
       "      <td>0.466638</td>\n",
       "      <td>0.528683</td>\n",
       "      <td>0.326940</td>\n",
       "      <td>0.347330</td>\n",
       "      <td>0.452033</td>\n",
       "      <td>0.500666</td>\n",
       "      <td>0.408247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>164.662933</td>\n",
       "      <td>18.447191</td>\n",
       "      <td>2.258896</td>\n",
       "      <td>8.766978</td>\n",
       "      <td>-1.978719</td>\n",
       "      <td>3.208094</td>\n",
       "      <td>-4.836560</td>\n",
       "      <td>3.958564</td>\n",
       "      <td>3.583583</td>\n",
       "      <td>5.426387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.497254</td>\n",
       "      <td>0.439649</td>\n",
       "      <td>0.530119</td>\n",
       "      <td>0.586929</td>\n",
       "      <td>0.559389</td>\n",
       "      <td>0.487167</td>\n",
       "      <td>0.422263</td>\n",
       "      <td>0.381106</td>\n",
       "      <td>0.419188</td>\n",
       "      <td>0.415870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>67.973389</td>\n",
       "      <td>-77.092560</td>\n",
       "      <td>20.854347</td>\n",
       "      <td>3.179512</td>\n",
       "      <td>-0.732732</td>\n",
       "      <td>8.882547</td>\n",
       "      <td>7.136349</td>\n",
       "      <td>-12.011120</td>\n",
       "      <td>-2.628152</td>\n",
       "      <td>0.461927</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065206</td>\n",
       "      <td>0.115020</td>\n",
       "      <td>0.143318</td>\n",
       "      <td>0.126561</td>\n",
       "      <td>0.091858</td>\n",
       "      <td>0.099164</td>\n",
       "      <td>0.161563</td>\n",
       "      <td>0.226875</td>\n",
       "      <td>0.217660</td>\n",
       "      <td>0.115195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>199.847290</td>\n",
       "      <td>2.052064</td>\n",
       "      <td>10.958324</td>\n",
       "      <td>2.982365</td>\n",
       "      <td>-4.694814</td>\n",
       "      <td>-5.742703</td>\n",
       "      <td>-17.959709</td>\n",
       "      <td>14.001516</td>\n",
       "      <td>15.751791</td>\n",
       "      <td>3.562183</td>\n",
       "      <td>...</td>\n",
       "      <td>1.368673</td>\n",
       "      <td>1.202957</td>\n",
       "      <td>1.253259</td>\n",
       "      <td>1.266183</td>\n",
       "      <td>1.044170</td>\n",
       "      <td>0.663657</td>\n",
       "      <td>0.303062</td>\n",
       "      <td>0.444658</td>\n",
       "      <td>0.695424</td>\n",
       "      <td>0.751368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>98.552094</td>\n",
       "      <td>-53.283867</td>\n",
       "      <td>39.570427</td>\n",
       "      <td>1.234147</td>\n",
       "      <td>-11.877034</td>\n",
       "      <td>0.053518</td>\n",
       "      <td>-1.286855</td>\n",
       "      <td>2.424939</td>\n",
       "      <td>10.428095</td>\n",
       "      <td>4.580007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.326343</td>\n",
       "      <td>0.317389</td>\n",
       "      <td>0.265434</td>\n",
       "      <td>0.206924</td>\n",
       "      <td>0.172030</td>\n",
       "      <td>0.152062</td>\n",
       "      <td>0.127119</td>\n",
       "      <td>0.129681</td>\n",
       "      <td>0.161393</td>\n",
       "      <td>0.161473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>105.964279</td>\n",
       "      <td>-50.897366</td>\n",
       "      <td>24.017075</td>\n",
       "      <td>2.425287</td>\n",
       "      <td>7.248587</td>\n",
       "      <td>-0.906617</td>\n",
       "      <td>2.971707</td>\n",
       "      <td>-4.050764</td>\n",
       "      <td>10.607948</td>\n",
       "      <td>1.717683</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253876</td>\n",
       "      <td>0.272664</td>\n",
       "      <td>0.264752</td>\n",
       "      <td>0.251754</td>\n",
       "      <td>0.200410</td>\n",
       "      <td>0.068831</td>\n",
       "      <td>0.096031</td>\n",
       "      <td>0.118088</td>\n",
       "      <td>0.086718</td>\n",
       "      <td>0.079193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          mfcc1      mfcc2      mfcc3      mfcc4      mfcc5      mfcc6  \\\n",
       "0     88.547943 -34.731178  17.439774   3.966827 -17.346939  18.881588   \n",
       "1    130.248093 -18.175362  -7.527256  -1.821126  -0.783999   9.139212   \n",
       "2     68.611404 -30.707958  43.091286  -5.395578 -31.639091  25.854515   \n",
       "3    124.010841 -26.582684   4.632347  -2.877658  -2.610994   1.804899   \n",
       "4     87.647217 -33.906952   0.952698 -12.743137 -30.600828  29.831501   \n",
       "..          ...        ...        ...        ...        ...        ...   \n",
       "895  164.662933  18.447191   2.258896   8.766978  -1.978719   3.208094   \n",
       "896   67.973389 -77.092560  20.854347   3.179512  -0.732732   8.882547   \n",
       "897  199.847290   2.052064  10.958324   2.982365  -4.694814  -5.742703   \n",
       "898   98.552094 -53.283867  39.570427   1.234147 -11.877034   0.053518   \n",
       "899  105.964279 -50.897366  24.017075   2.425287   7.248587  -0.906617   \n",
       "\n",
       "         mfcc7      mfcc8      mfcc9    mfcc10  ...     cqt51     cqt52  \\\n",
       "0   -17.580509   8.225138   2.163004 -6.991869  ...  0.080291  0.162481   \n",
       "1   -30.255112 -18.019503  -3.269579  6.034618  ...  0.317061  0.272742   \n",
       "2   -19.372128  12.241970  -3.681171 -0.359709  ...  0.276001  0.268128   \n",
       "3    -2.408908   5.523919  -0.094534  6.949768  ...  0.438422  0.535192   \n",
       "4   -26.453606   7.694873   0.659293 -6.993608  ...  0.261029  0.448852   \n",
       "..         ...        ...        ...       ...  ...       ...       ...   \n",
       "895  -4.836560   3.958564   3.583583  5.426387  ...  0.497254  0.439649   \n",
       "896   7.136349 -12.011120  -2.628152  0.461927  ...  0.065206  0.115020   \n",
       "897 -17.959709  14.001516  15.751791  3.562183  ...  1.368673  1.202957   \n",
       "898  -1.286855   2.424939  10.428095  4.580007  ...  0.326343  0.317389   \n",
       "899   2.971707  -4.050764  10.607948  1.717683  ...  0.253876  0.272664   \n",
       "\n",
       "        cqt53     cqt54     cqt55     cqt56     cqt57     cqt58     cqt59  \\\n",
       "0    0.128590  0.253865  0.286246  0.232347  0.166034  0.149659  0.175466   \n",
       "1    0.214996  0.163759  0.185034  0.284470  0.427768  0.583855  0.714654   \n",
       "2    0.329467  0.240955  0.215759  0.290983  0.327005  0.241768  0.163038   \n",
       "3    0.555842  0.328036  0.101016  0.362609  0.401901  0.259996  0.146674   \n",
       "4    0.387767  0.466638  0.528683  0.326940  0.347330  0.452033  0.500666   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "895  0.530119  0.586929  0.559389  0.487167  0.422263  0.381106  0.419188   \n",
       "896  0.143318  0.126561  0.091858  0.099164  0.161563  0.226875  0.217660   \n",
       "897  1.253259  1.266183  1.044170  0.663657  0.303062  0.444658  0.695424   \n",
       "898  0.265434  0.206924  0.172030  0.152062  0.127119  0.129681  0.161393   \n",
       "899  0.264752  0.251754  0.200410  0.068831  0.096031  0.118088  0.086718   \n",
       "\n",
       "        cqt60  \n",
       "0    0.264108  \n",
       "1    0.804361  \n",
       "2    0.190981  \n",
       "3    0.301535  \n",
       "4    0.408247  \n",
       "..        ...  \n",
       "895  0.415870  \n",
       "896  0.115195  \n",
       "897  0.751368  \n",
       "898  0.161473  \n",
       "899  0.079193  \n",
       "\n",
       "[900 rows x 101 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180,)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 101)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>mfcc4</th>\n",
       "      <th>mfcc5</th>\n",
       "      <th>mfcc6</th>\n",
       "      <th>mfcc7</th>\n",
       "      <th>mfcc8</th>\n",
       "      <th>mfcc9</th>\n",
       "      <th>mfcc10</th>\n",
       "      <th>...</th>\n",
       "      <th>cqt51</th>\n",
       "      <th>cqt52</th>\n",
       "      <th>cqt53</th>\n",
       "      <th>cqt54</th>\n",
       "      <th>cqt55</th>\n",
       "      <th>cqt56</th>\n",
       "      <th>cqt57</th>\n",
       "      <th>cqt58</th>\n",
       "      <th>cqt59</th>\n",
       "      <th>cqt60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.314944</td>\n",
       "      <td>-80.155304</td>\n",
       "      <td>31.539179</td>\n",
       "      <td>-15.789383</td>\n",
       "      <td>12.516445</td>\n",
       "      <td>-6.611809</td>\n",
       "      <td>2.372676</td>\n",
       "      <td>-6.058306</td>\n",
       "      <td>-3.496922</td>\n",
       "      <td>-4.178765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018976</td>\n",
       "      <td>0.024869</td>\n",
       "      <td>0.022892</td>\n",
       "      <td>0.014639</td>\n",
       "      <td>0.024999</td>\n",
       "      <td>0.023980</td>\n",
       "      <td>0.013636</td>\n",
       "      <td>0.017384</td>\n",
       "      <td>0.026579</td>\n",
       "      <td>0.022777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>54.503723</td>\n",
       "      <td>-41.367424</td>\n",
       "      <td>48.399117</td>\n",
       "      <td>-9.767862</td>\n",
       "      <td>-23.927776</td>\n",
       "      <td>14.609686</td>\n",
       "      <td>-10.254643</td>\n",
       "      <td>6.549664</td>\n",
       "      <td>0.189328</td>\n",
       "      <td>1.122744</td>\n",
       "      <td>...</td>\n",
       "      <td>0.212671</td>\n",
       "      <td>0.213660</td>\n",
       "      <td>0.200182</td>\n",
       "      <td>0.181743</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0.125272</td>\n",
       "      <td>0.146561</td>\n",
       "      <td>0.155583</td>\n",
       "      <td>0.139843</td>\n",
       "      <td>0.123858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>55.966881</td>\n",
       "      <td>-37.387817</td>\n",
       "      <td>47.005547</td>\n",
       "      <td>-0.751225</td>\n",
       "      <td>-9.511966</td>\n",
       "      <td>3.952195</td>\n",
       "      <td>0.353659</td>\n",
       "      <td>6.933780</td>\n",
       "      <td>-6.587204</td>\n",
       "      <td>4.317513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051018</td>\n",
       "      <td>0.057589</td>\n",
       "      <td>0.054120</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>0.049560</td>\n",
       "      <td>0.049883</td>\n",
       "      <td>0.040081</td>\n",
       "      <td>0.034032</td>\n",
       "      <td>0.030285</td>\n",
       "      <td>0.027783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>129.956497</td>\n",
       "      <td>-27.350931</td>\n",
       "      <td>-3.110487</td>\n",
       "      <td>5.861757</td>\n",
       "      <td>5.723415</td>\n",
       "      <td>4.147360</td>\n",
       "      <td>13.904932</td>\n",
       "      <td>2.406283</td>\n",
       "      <td>-0.162421</td>\n",
       "      <td>-3.731496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.212201</td>\n",
       "      <td>0.284335</td>\n",
       "      <td>0.271481</td>\n",
       "      <td>0.209435</td>\n",
       "      <td>0.272691</td>\n",
       "      <td>0.277367</td>\n",
       "      <td>0.247612</td>\n",
       "      <td>0.198224</td>\n",
       "      <td>0.185756</td>\n",
       "      <td>0.132383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>38.863163</td>\n",
       "      <td>-55.595146</td>\n",
       "      <td>45.313419</td>\n",
       "      <td>-8.766414</td>\n",
       "      <td>-24.194538</td>\n",
       "      <td>13.574966</td>\n",
       "      <td>-8.415053</td>\n",
       "      <td>10.158276</td>\n",
       "      <td>-9.115362</td>\n",
       "      <td>2.618633</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106329</td>\n",
       "      <td>0.126158</td>\n",
       "      <td>0.112372</td>\n",
       "      <td>0.127090</td>\n",
       "      <td>0.118933</td>\n",
       "      <td>0.125747</td>\n",
       "      <td>0.115665</td>\n",
       "      <td>0.107891</td>\n",
       "      <td>0.104901</td>\n",
       "      <td>0.110099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>5.145700</td>\n",
       "      <td>-65.987762</td>\n",
       "      <td>40.869423</td>\n",
       "      <td>-18.713455</td>\n",
       "      <td>21.685717</td>\n",
       "      <td>-10.311221</td>\n",
       "      <td>9.841274</td>\n",
       "      <td>-7.008872</td>\n",
       "      <td>-5.599904</td>\n",
       "      <td>-0.157352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054428</td>\n",
       "      <td>0.023639</td>\n",
       "      <td>0.016446</td>\n",
       "      <td>0.042021</td>\n",
       "      <td>0.044275</td>\n",
       "      <td>0.026853</td>\n",
       "      <td>0.028605</td>\n",
       "      <td>0.036752</td>\n",
       "      <td>0.025814</td>\n",
       "      <td>0.021942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>63.545021</td>\n",
       "      <td>-48.544891</td>\n",
       "      <td>27.680458</td>\n",
       "      <td>-4.523205</td>\n",
       "      <td>-5.682001</td>\n",
       "      <td>5.286124</td>\n",
       "      <td>-1.581363</td>\n",
       "      <td>-0.671593</td>\n",
       "      <td>-2.775605</td>\n",
       "      <td>3.084220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060647</td>\n",
       "      <td>0.057623</td>\n",
       "      <td>0.065459</td>\n",
       "      <td>0.061655</td>\n",
       "      <td>0.049629</td>\n",
       "      <td>0.042573</td>\n",
       "      <td>0.032021</td>\n",
       "      <td>0.018934</td>\n",
       "      <td>0.026061</td>\n",
       "      <td>0.031315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>120.980637</td>\n",
       "      <td>-49.460346</td>\n",
       "      <td>28.065496</td>\n",
       "      <td>-4.179470</td>\n",
       "      <td>9.534807</td>\n",
       "      <td>-2.758196</td>\n",
       "      <td>-6.629617</td>\n",
       "      <td>-3.639332</td>\n",
       "      <td>3.070858</td>\n",
       "      <td>-0.821289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.309850</td>\n",
       "      <td>0.278900</td>\n",
       "      <td>0.238843</td>\n",
       "      <td>0.200179</td>\n",
       "      <td>0.174700</td>\n",
       "      <td>0.175035</td>\n",
       "      <td>0.176176</td>\n",
       "      <td>0.149111</td>\n",
       "      <td>0.138299</td>\n",
       "      <td>0.227936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>30.062765</td>\n",
       "      <td>-47.433411</td>\n",
       "      <td>51.785614</td>\n",
       "      <td>6.403006</td>\n",
       "      <td>-54.266167</td>\n",
       "      <td>11.053203</td>\n",
       "      <td>-25.836227</td>\n",
       "      <td>15.351446</td>\n",
       "      <td>-2.097059</td>\n",
       "      <td>-6.517249</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277985</td>\n",
       "      <td>0.211103</td>\n",
       "      <td>0.228536</td>\n",
       "      <td>0.216290</td>\n",
       "      <td>0.177742</td>\n",
       "      <td>0.165194</td>\n",
       "      <td>0.128024</td>\n",
       "      <td>0.108679</td>\n",
       "      <td>0.084226</td>\n",
       "      <td>0.059343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>57.082703</td>\n",
       "      <td>-30.816257</td>\n",
       "      <td>10.576953</td>\n",
       "      <td>-15.985017</td>\n",
       "      <td>-32.946739</td>\n",
       "      <td>36.684029</td>\n",
       "      <td>-23.928074</td>\n",
       "      <td>4.670375</td>\n",
       "      <td>5.815710</td>\n",
       "      <td>-2.296181</td>\n",
       "      <td>...</td>\n",
       "      <td>0.263369</td>\n",
       "      <td>0.365351</td>\n",
       "      <td>0.293937</td>\n",
       "      <td>0.300120</td>\n",
       "      <td>0.274365</td>\n",
       "      <td>0.249961</td>\n",
       "      <td>0.332018</td>\n",
       "      <td>0.250429</td>\n",
       "      <td>0.297802</td>\n",
       "      <td>0.247328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>720 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          mfcc1      mfcc2      mfcc3      mfcc4      mfcc5      mfcc6  \\\n",
       "10     4.314944 -80.155304  31.539179 -15.789383  12.516445  -6.611809   \n",
       "334   54.503723 -41.367424  48.399117  -9.767862 -23.927776  14.609686   \n",
       "244   55.966881 -37.387817  47.005547  -0.751225  -9.511966   3.952195   \n",
       "678  129.956497 -27.350931  -3.110487   5.861757   5.723415   4.147360   \n",
       "306   38.863163 -55.595146  45.313419  -8.766414 -24.194538  13.574966   \n",
       "..          ...        ...        ...        ...        ...        ...   \n",
       "106    5.145700 -65.987762  40.869423 -18.713455  21.685717 -10.311221   \n",
       "270   63.545021 -48.544891  27.680458  -4.523205  -5.682001   5.286124   \n",
       "860  120.980637 -49.460346  28.065496  -4.179470   9.534807  -2.758196   \n",
       "435   30.062765 -47.433411  51.785614   6.403006 -54.266167  11.053203   \n",
       "102   57.082703 -30.816257  10.576953 -15.985017 -32.946739  36.684029   \n",
       "\n",
       "         mfcc7      mfcc8     mfcc9    mfcc10  ...     cqt51     cqt52  \\\n",
       "10    2.372676  -6.058306 -3.496922 -4.178765  ...  0.018976  0.024869   \n",
       "334 -10.254643   6.549664  0.189328  1.122744  ...  0.212671  0.213660   \n",
       "244   0.353659   6.933780 -6.587204  4.317513  ...  0.051018  0.057589   \n",
       "678  13.904932   2.406283 -0.162421 -3.731496  ...  0.212201  0.284335   \n",
       "306  -8.415053  10.158276 -9.115362  2.618633  ...  0.106329  0.126158   \n",
       "..         ...        ...       ...       ...  ...       ...       ...   \n",
       "106   9.841274  -7.008872 -5.599904 -0.157352  ...  0.054428  0.023639   \n",
       "270  -1.581363  -0.671593 -2.775605  3.084220  ...  0.060647  0.057623   \n",
       "860  -6.629617  -3.639332  3.070858 -0.821289  ...  0.309850  0.278900   \n",
       "435 -25.836227  15.351446 -2.097059 -6.517249  ...  0.277985  0.211103   \n",
       "102 -23.928074   4.670375  5.815710 -2.296181  ...  0.263369  0.365351   \n",
       "\n",
       "        cqt53     cqt54     cqt55     cqt56     cqt57     cqt58     cqt59  \\\n",
       "10   0.022892  0.014639  0.024999  0.023980  0.013636  0.017384  0.026579   \n",
       "334  0.200182  0.181743  0.152893  0.125272  0.146561  0.155583  0.139843   \n",
       "244  0.054120  0.049960  0.049560  0.049883  0.040081  0.034032  0.030285   \n",
       "678  0.271481  0.209435  0.272691  0.277367  0.247612  0.198224  0.185756   \n",
       "306  0.112372  0.127090  0.118933  0.125747  0.115665  0.107891  0.104901   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "106  0.016446  0.042021  0.044275  0.026853  0.028605  0.036752  0.025814   \n",
       "270  0.065459  0.061655  0.049629  0.042573  0.032021  0.018934  0.026061   \n",
       "860  0.238843  0.200179  0.174700  0.175035  0.176176  0.149111  0.138299   \n",
       "435  0.228536  0.216290  0.177742  0.165194  0.128024  0.108679  0.084226   \n",
       "102  0.293937  0.300120  0.274365  0.249961  0.332018  0.250429  0.297802   \n",
       "\n",
       "        cqt60  \n",
       "10   0.022777  \n",
       "334  0.123858  \n",
       "244  0.027783  \n",
       "678  0.132383  \n",
       "306  0.110099  \n",
       "..        ...  \n",
       "106  0.021942  \n",
       "270  0.031315  \n",
       "860  0.227936  \n",
       "435  0.059343  \n",
       "102  0.247328  \n",
       "\n",
       "[720 rows x 101 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180,)\n",
      "(720, 101, 1)\n",
      "(180, 101, 1)\n"
     ]
    }
   ],
   "source": [
    "lb = LabelEncoder()\n",
    "X_train = np.expand_dims(X_train, axis=2)\n",
    "X_test = np.expand_dims(X_test, axis=2)\n",
    "print(y_test.shape)\n",
    "y_test = tf.keras.utils.to_categorical(lb.fit_transform(y_test))\n",
    "y_train = tf.keras.utils.to_categorical(lb.fit_transform(y_train))\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make RNN model\n",
    "def build_model():\n",
    "    model = models.Sequential(\n",
    "        [\n",
    "            layers.SimpleRNN(64,activation='tanh',input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True),\n",
    "            layers.Dense(32, activation=\"relu\"),\n",
    "\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(64, activation=\"relu\"),\n",
    "            layers.Dense(32, activation=\"relu\"),\n",
    "\n",
    "            layers.BatchNormalization(),\n",
    "\n",
    "            layers.Dense(5, activation=\"softmax\"),\n",
    "            # layers.SimpleRNN(64,activation='tanh',input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True),\n",
    "            # layers.Dense(32, activation=\"relu\", activity_regularizer=tf.keras.regularizers.l2(1e-4)),\n",
    "\n",
    "            # layers.Flatten(),\n",
    "            # layers.Dense(64, activation=\"relu\", activity_regularizer=tf.keras.regularizers.l2(1e-4)),\n",
    "            # layers.Dense(32, activation=\"relu\", activity_regularizer=tf.keras.regularizers.l2(1e-4)),\n",
    "\n",
    "            # layers.Dense(5, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_7 (SimpleRNN)    (None, 101, 64)           4224      \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 101, 32)           2080      \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 3232)              0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 64)                206912    \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 32)                128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 5)                 165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 215589 (842.14 KB)\n",
      "Trainable params: 215525 (841.89 KB)\n",
      "Non-trainable params: 64 (256.00 Byte)\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rafli/anaconda3/envs/tf/lib/python3.11/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()\n",
    "model.save('../modelh5/model_rnn_nontuning.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 2s 25ms/step - loss: 1.2515 - acc: 0.5556 - val_loss: 1.3824 - val_acc: 0.4222\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.7414 - acc: 0.7458 - val_loss: 1.2666 - val_acc: 0.5556\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5966 - acc: 0.8125 - val_loss: 1.1722 - val_acc: 0.7000\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5051 - acc: 0.8556 - val_loss: 1.0824 - val_acc: 0.7778\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.4417 - acc: 0.8750 - val_loss: 1.0015 - val_acc: 0.7778\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.3880 - acc: 0.8889 - val_loss: 0.9244 - val_acc: 0.7944\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.3608 - acc: 0.9208 - val_loss: 0.8474 - val_acc: 0.8278\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.3165 - acc: 0.9403 - val_loss: 0.7917 - val_acc: 0.8333\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.2847 - acc: 0.9389 - val_loss: 0.7163 - val_acc: 0.8611\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.2495 - acc: 0.9667 - val_loss: 0.6705 - val_acc: 0.8556\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.2303 - acc: 0.9694 - val_loss: 0.6225 - val_acc: 0.8611\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.2033 - acc: 0.9792 - val_loss: 0.5674 - val_acc: 0.8889\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.1834 - acc: 0.9819 - val_loss: 0.5375 - val_acc: 0.8833\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.1779 - acc: 0.9875 - val_loss: 0.4874 - val_acc: 0.8944\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.1536 - acc: 0.9944 - val_loss: 0.4601 - val_acc: 0.8889\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.1383 - acc: 0.9944 - val_loss: 0.4358 - val_acc: 0.8944\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.1285 - acc: 1.0000 - val_loss: 0.4132 - val_acc: 0.8944\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.1194 - acc: 1.0000 - val_loss: 0.3870 - val_acc: 0.8944\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.1111 - acc: 0.9986 - val_loss: 0.3790 - val_acc: 0.8889\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0982 - acc: 0.9986 - val_loss: 0.3588 - val_acc: 0.9000\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0958 - acc: 1.0000 - val_loss: 0.3447 - val_acc: 0.8944\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0882 - acc: 0.9986 - val_loss: 0.3323 - val_acc: 0.8889\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0838 - acc: 0.9986 - val_loss: 0.3265 - val_acc: 0.9000\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0833 - acc: 1.0000 - val_loss: 0.3207 - val_acc: 0.8944\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0723 - acc: 1.0000 - val_loss: 0.3090 - val_acc: 0.9056\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0704 - acc: 1.0000 - val_loss: 0.2995 - val_acc: 0.8944\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0643 - acc: 1.0000 - val_loss: 0.3007 - val_acc: 0.9000\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0586 - acc: 1.0000 - val_loss: 0.2893 - val_acc: 0.9000\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0617 - acc: 1.0000 - val_loss: 0.2855 - val_acc: 0.9111\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0548 - acc: 0.9986 - val_loss: 0.2783 - val_acc: 0.9167\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0530 - acc: 1.0000 - val_loss: 0.2796 - val_acc: 0.9222\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0517 - acc: 1.0000 - val_loss: 0.2828 - val_acc: 0.9167\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0450 - acc: 1.0000 - val_loss: 0.2742 - val_acc: 0.9167\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0443 - acc: 1.0000 - val_loss: 0.2724 - val_acc: 0.9222\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0455 - acc: 1.0000 - val_loss: 0.2777 - val_acc: 0.9167\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0432 - acc: 1.0000 - val_loss: 0.2701 - val_acc: 0.9222\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0420 - acc: 1.0000 - val_loss: 0.2671 - val_acc: 0.9222\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0384 - acc: 1.0000 - val_loss: 0.2632 - val_acc: 0.9222\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0408 - acc: 1.0000 - val_loss: 0.2648 - val_acc: 0.9222\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0353 - acc: 1.0000 - val_loss: 0.2640 - val_acc: 0.9222\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0320 - acc: 1.0000 - val_loss: 0.2637 - val_acc: 0.9222\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0316 - acc: 1.0000 - val_loss: 0.2584 - val_acc: 0.9278\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0321 - acc: 1.0000 - val_loss: 0.2613 - val_acc: 0.9278\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0312 - acc: 1.0000 - val_loss: 0.2564 - val_acc: 0.9278\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0300 - acc: 1.0000 - val_loss: 0.2565 - val_acc: 0.9278\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0272 - acc: 1.0000 - val_loss: 0.2561 - val_acc: 0.9278\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0262 - acc: 1.0000 - val_loss: 0.2529 - val_acc: 0.9278\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0284 - acc: 1.0000 - val_loss: 0.2533 - val_acc: 0.9333\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0260 - acc: 1.0000 - val_loss: 0.2540 - val_acc: 0.9222\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0245 - acc: 1.0000 - val_loss: 0.2527 - val_acc: 0.9222\n"
     ]
    }
   ],
   "source": [
    "optimazer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimazer, loss='categorical_crossentropy', metrics=['acc'])\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
    "# history = model.fit(X_train, y_train, epochs=35, batch_size=16, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 5ms/step - loss: 0.2527 - acc: 0.9222\n",
      "Accuracy on test set is: 0.9222221970558167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate model on test set\n",
    "test_error, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Accuracy on test set is: {}\".format(test_accuracy))\n",
    "\n",
    "\n",
    "# plot accuracy/error for training and validation\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(history.history['acc'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_acc'], label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uri = \"../modelh5/model_RNN.h5\"\n",
    "model.save(model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[31,  2,  1,  1,  0],\n",
       "       [ 1, 25,  2,  3,  0],\n",
       "       [ 0,  0, 37,  0,  1],\n",
       "       [ 1,  0,  2, 32,  0],\n",
       "       [ 0,  0,  0,  0, 41]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = model.predict(X_test)\n",
    "y_p = np.argmax(y_pred, axis=1)\n",
    "y_t = np.argmax(y_test, axis=1)\n",
    "cm = confusion_matrix(y_t, y_p)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.91        35\n",
      "           1       0.93      0.81      0.86        31\n",
      "           2       0.88      0.97      0.93        38\n",
      "           3       0.89      0.91      0.90        35\n",
      "           4       0.98      1.00      0.99        41\n",
      "\n",
      "    accuracy                           0.92       180\n",
      "   macro avg       0.92      0.92      0.92       180\n",
      "weighted avg       0.92      0.92      0.92       180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_t, y_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_7 (SimpleRNN)    (None, 101, 64)           4224      \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 101, 32)           2080      \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 3232)              0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 64)                206912    \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 32)                128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 5)                 165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 215589 (842.14 KB)\n",
      "Trainable params: 215525 (841.89 KB)\n",
      "Non-trainable params: 64 (256.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model(model_uri)\n",
    "new_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "import json\n",
    "header = 'filename'\n",
    "for i in range(1, 41):\n",
    "    header += f' mfcc{i}'\n",
    "header += ' rms'\n",
    "for i in range(1, 61):\n",
    "  header += f' cqt{i}'\n",
    "header += ' label'\n",
    "header = header.split()\n",
    "\n",
    "\n",
    "def extract_mfcc(audiofile):\n",
    "    file = open('test.csv', 'w', newline='')\n",
    "    with file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(header)\n",
    "    y, sr = librosa.load(audiofile, mono=True, duration=3, sr=8000)\n",
    "    coeffs = wavedec(y, 'db1', level=10)\n",
    "    cA,cD10,cD9,cD8,cD7,cD6,cD5,cD4,cD3,cD2, cD1 = coeffs\n",
    "    mfcc = librosa.feature.mfcc(y=cD5, sr=8000, n_mfcc=40, n_fft=2048, hop_length=512, n_mels=128)\n",
    "    rms = librosa.feature.rms(y=cD5)[0]\n",
    "    cqt = np.abs(librosa.cqt(y=cD5, sr=sr, n_bins=60)) \n",
    "    combined_features = np.concatenate((mfcc, rms.reshape(1, -1), cqt), axis=0)\n",
    "    to_append = f'Signal'\n",
    "    for e in combined_features:\n",
    "        to_append += f' {np.mean(e.T, axis=0)}'\n",
    "    file = open('test.csv', 'a', newline='')\n",
    "    with file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(to_append.split())\n",
    "\n",
    "def predict(audio):\n",
    "    model = tf.keras.models.load_model(model_uri)\n",
    "    extract_mfcc(audio)\n",
    "    data = pd.read_csv('test.csv')\n",
    "    df = data.drop(['label', 'filename'], axis=1)\n",
    "    pred = model.predict(df)\n",
    "    class_labels = ['AS', 'MR', 'MS', 'MVP', 'N']\n",
    "    cek = np.argmax(pred[0])\n",
    "    print(pred[0])\n",
    "    print(cek)\n",
    "    print(f'Predicted class: {class_labels[cek]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rafli/anaconda3/envs/tf/lib/python3.11/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=640\n",
      "  warnings.warn(\n",
      "/home/rafli/anaconda3/envs/tf/lib/python3.11/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=512 is too large for input signal of length=320\n",
      "  warnings.warn(\n",
      "/home/rafli/anaconda3/envs/tf/lib/python3.11/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=512 is too large for input signal of length=160\n",
      "  warnings.warn(\n",
      "/home/rafli/anaconda3/envs/tf/lib/python3.11/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=512 is too large for input signal of length=80\n",
      "  warnings.warn(\n",
      "/home/rafli/anaconda3/envs/tf/lib/python3.11/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=512 is too large for input signal of length=40\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 184ms/step\n",
      "[5.4051769e-03 5.0802394e-03 5.5228127e-03 9.8300928e-01 9.8247454e-04]\n",
      "3\n",
      "Predicted class: MVP\n"
     ]
    }
   ],
   "source": [
    "predict('../data/training/MVP/New_MVP_004.wav')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

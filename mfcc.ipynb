{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-27 18:22:40.817543: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import math\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import models, layers\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATASET_PATH = \"data/training/\"\n",
    "JSON_PATH = \"data.json\"\n",
    "SAMPLE_RATE = 22050\n",
    "TRACK_DURATION = 5 # measured in seconds\n",
    "SAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_mfcc(dataset_path, json_path, n_mfcc=13, n_fft=2048, hop_length=512, num_segments=5):\n",
    "\n",
    "    data = {\n",
    "        \"mapping\": [],\n",
    "        \"mfcc\": [],\n",
    "        \"labels\": []\n",
    "    }\n",
    "\n",
    "    num_samples_per_segment = int(SAMPLES_PER_TRACK / num_segments)\n",
    "    expected_num_mfcc_vectors_per_segment = math.ceil(num_samples_per_segment / hop_length)\n",
    "\n",
    "    # loop through all genre sub-folder\n",
    "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
    "\n",
    "        # ensure we're processing a genre sub-folder level\n",
    "        if dirpath is not dataset_path:\n",
    "\n",
    "            # save genre label (i.e., sub-folder name) in the mapping\n",
    "            semantic_label = dirpath.split(\"/\")[-1]\n",
    "            data[\"mapping\"].append(semantic_label)\n",
    "            print(\"\\nProcessing: {}\".format(semantic_label))\n",
    "\n",
    "            # process all audio files in genre sub-dir\n",
    "            for f in filenames:\n",
    "\n",
    "                # load audio file\n",
    "                file_path = os.path.join(dirpath, f)\n",
    "                signal, sr = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "\n",
    "                # process all segments of audio file\n",
    "                for d in range(num_segments):\n",
    "\n",
    "                    # calculate start and finish sample for current segment\n",
    "                    start = num_samples_per_segment * d\n",
    "                    finish = start + num_samples_per_segment\n",
    "\n",
    "                    # extract mfcc\n",
    "                    mfcc = librosa.feature.mfcc(y=signal,\n",
    "                                                sr=SAMPLE_RATE, n_mfcc=20, n_fft=2048, hop_length=512, n_mels=128)\n",
    "\n",
    "                    mfcc = mfcc.T\n",
    "\n",
    "                    # store only mfcc feature with expected number of vectors\n",
    "                    if len(mfcc) == expected_num_mfcc_vectors_per_segment:\n",
    "                        data[\"mfcc\"].append(mfcc.tolist())\n",
    "                        data[\"labels\"].append(i-1)\n",
    "                        print(\"{}, segment:{}\".format(file_path, d+1))\n",
    "\n",
    "    # save MFCCs to json file\n",
    "    with open(json_path, \"w\") as fp:\n",
    "        json.dump(data, fp, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: MR\n",
      "\n",
      "Processing: AS\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m save_mfcc(DATASET_PATH, JSON_PATH, num_segments\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[1], line 38\u001b[0m, in \u001b[0;36msave_mfcc\u001b[0;34m(dataset_path, json_path, n_mfcc, n_fft, hop_length, num_segments)\u001b[0m\n\u001b[1;32m     35\u001b[0m finish \u001b[39m=\u001b[39m start \u001b[39m+\u001b[39m num_samples_per_segment\n\u001b[1;32m     37\u001b[0m \u001b[39m# extract mfcc\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m mfcc \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39;49mfeature\u001b[39m.\u001b[39;49mmfcc(y\u001b[39m=\u001b[39;49msignal,\n\u001b[1;32m     39\u001b[0m                             sr\u001b[39m=\u001b[39;49mSAMPLE_RATE, n_mfcc\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m, n_fft\u001b[39m=\u001b[39;49m\u001b[39m2048\u001b[39;49m, hop_length\u001b[39m=\u001b[39;49m\u001b[39m512\u001b[39;49m, n_mels\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m)\n\u001b[1;32m     41\u001b[0m mfcc \u001b[39m=\u001b[39m mfcc\u001b[39m.\u001b[39mT\n\u001b[1;32m     43\u001b[0m \u001b[39m# store only mfcc feature with expected number of vectors\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.10/site-packages/librosa/feature/spectral.py:2002\u001b[0m, in \u001b[0;36mmfcc\u001b[0;34m(y, sr, S, n_mfcc, dct_type, norm, lifter, **kwargs)\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Mel-frequency cepstral coefficients (MFCCs)\u001b[39;00m\n\u001b[1;32m   1856\u001b[0m \n\u001b[1;32m   1857\u001b[0m \u001b[39m.. warning:: If multi-channel audio input ``y`` is provided, the MFCC\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1997\u001b[0m \u001b[39m>>> fig.colorbar(img2, ax=[ax[1]])\u001b[39;00m\n\u001b[1;32m   1998\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2000\u001b[0m \u001b[39mif\u001b[39;00m S \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2001\u001b[0m     \u001b[39m# multichannel behavior may be different due to relative noise floor differences between channels\u001b[39;00m\n\u001b[0;32m-> 2002\u001b[0m     S \u001b[39m=\u001b[39m power_to_db(melspectrogram(y\u001b[39m=\u001b[39;49my, sr\u001b[39m=\u001b[39;49msr, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n\u001b[1;32m   2004\u001b[0m M: np\u001b[39m.\u001b[39mndarray \u001b[39m=\u001b[39m scipy\u001b[39m.\u001b[39mfftpack\u001b[39m.\u001b[39mdct(S, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m, \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39mdct_type, norm\u001b[39m=\u001b[39mnorm)[\n\u001b[1;32m   2005\u001b[0m     \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, :n_mfcc, :\n\u001b[1;32m   2006\u001b[0m ]\n\u001b[1;32m   2008\u001b[0m \u001b[39mif\u001b[39;00m lifter \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   2009\u001b[0m     \u001b[39m# shape lifter for broadcasting\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.10/site-packages/librosa/feature/spectral.py:2159\u001b[0m, in \u001b[0;36mmelspectrogram\u001b[0;34m(y, sr, S, n_fft, hop_length, win_length, window, center, pad_mode, power, **kwargs)\u001b[0m\n\u001b[1;32m   2156\u001b[0m \u001b[39m# Build a Mel filter\u001b[39;00m\n\u001b[1;32m   2157\u001b[0m mel_basis \u001b[39m=\u001b[39m filters\u001b[39m.\u001b[39mmel(sr\u001b[39m=\u001b[39msr, n_fft\u001b[39m=\u001b[39mn_fft, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m-> 2159\u001b[0m melspec: np\u001b[39m.\u001b[39mndarray \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49meinsum(\u001b[39m\"\u001b[39;49m\u001b[39m...ft,mf->...mt\u001b[39;49m\u001b[39m\"\u001b[39;49m, S, mel_basis, optimize\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   2160\u001b[0m \u001b[39mreturn\u001b[39;00m melspec\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.10/site-packages/numpy/core/einsumfunc.py:1419\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(out, optimize, *operands, **kwargs)\u001b[0m\n\u001b[1;32m   1416\u001b[0m     right_pos\u001b[39m.\u001b[39mappend(input_right\u001b[39m.\u001b[39mfind(s))\n\u001b[1;32m   1418\u001b[0m \u001b[39m# Contract!\u001b[39;00m\n\u001b[0;32m-> 1419\u001b[0m new_view \u001b[39m=\u001b[39m tensordot(\u001b[39m*\u001b[39;49mtmp_operands, axes\u001b[39m=\u001b[39;49m(\u001b[39mtuple\u001b[39;49m(left_pos), \u001b[39mtuple\u001b[39;49m(right_pos)))\n\u001b[1;32m   1421\u001b[0m \u001b[39m# Build a new view if needed\u001b[39;00m\n\u001b[1;32m   1422\u001b[0m \u001b[39mif\u001b[39;00m (tensor_result \u001b[39m!=\u001b[39m results_index) \u001b[39mor\u001b[39;00m handle_out:\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mtensordot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.10/site-packages/numpy/core/numeric.py:1138\u001b[0m, in \u001b[0;36mtensordot\u001b[0;34m(a, b, axes)\u001b[0m\n\u001b[1;32m   1136\u001b[0m at \u001b[39m=\u001b[39m a\u001b[39m.\u001b[39mtranspose(newaxes_a)\u001b[39m.\u001b[39mreshape(newshape_a)\n\u001b[1;32m   1137\u001b[0m bt \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mtranspose(newaxes_b)\u001b[39m.\u001b[39mreshape(newshape_b)\n\u001b[0;32m-> 1138\u001b[0m res \u001b[39m=\u001b[39m dot(at, bt)\n\u001b[1;32m   1139\u001b[0m \u001b[39mreturn\u001b[39;00m res\u001b[39m.\u001b[39mreshape(olda \u001b[39m+\u001b[39m oldb)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "save_mfcc(DATASET_PATH, JSON_PATH, num_segments=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "\n",
    "    with open(data_path, \"r\") as fp:\n",
    "        data = json.load(fp)\n",
    "\n",
    "    X = np.array(data[\"mfcc\"])\n",
    "    y = np.array(data[\"labels\"])\n",
    "    \n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(test_size, validation_size):\n",
    "    # load data\n",
    "    X, y = load_data(JSON_PATH)\n",
    "\n",
    "\n",
    "    # create train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "\n",
    "    # create train/validation split\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validation_size)\n",
    "\n",
    "    # add an axis to nd array\n",
    "    X_train = X_train[..., np.newaxis]\n",
    "    X_validation = X_validation[..., np.newaxis]\n",
    "    X_test = X_test[..., np.newaxis]\n",
    "\n",
    "    return X_train, X_validation, X_test, y_train, y_validation, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same', data_format='channels_first'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same', data_format='channels_first'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Conv2D(32, (2, 2), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same', data_format='channels_first'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 130, 20, 1)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(X_train\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      5\u001b[0m input_shape \u001b[39m=\u001b[39m (X_train[\u001b[39m1\u001b[39m], X_train[\u001b[39m2\u001b[39m], X_train[\u001b[39m3\u001b[39m])\n\u001b[0;32m----> 6\u001b[0m model \u001b[39m=\u001b[39m build_model(input_shape)\n\u001b[1;32m      8\u001b[0m optimazer \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.0001\u001b[39m)\n\u001b[1;32m      9\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39moptimazer, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m(input_shape)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild_model\u001b[39m(input_shape):\n\u001b[1;32m      2\u001b[0m     model \u001b[39m=\u001b[39m models\u001b[39m.\u001b[39mSequential()\n\u001b[0;32m----> 3\u001b[0m     model\u001b[39m.\u001b[39;49madd(layers\u001b[39m.\u001b[39;49mConv2D(\u001b[39m32\u001b[39;49m, (\u001b[39m3\u001b[39;49m, \u001b[39m3\u001b[39;49m), activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m, input_shape\u001b[39m=\u001b[39;49minput_shape))\n\u001b[1;32m      4\u001b[0m     model\u001b[39m.\u001b[39madd(layers\u001b[39m.\u001b[39mMaxPooling2D((\u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m), strides\u001b[39m=\u001b[39m(\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m), padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msame\u001b[39m\u001b[39m'\u001b[39m, data_format\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mchannels_first\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m      5\u001b[0m     model\u001b[39m.\u001b[39madd(layers\u001b[39m.\u001b[39mBatchNormalization())\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/trackable/base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    206\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/framework/tensor_shape.py:212\u001b[0m, in \u001b[0;36mDimension.__init__\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m     \u001b[39m# int(...) compensates for the int/long dichotomy on Python 2.X.\u001b[39;00m\n\u001b[1;32m    211\u001b[0m     \u001b[39m# TODO(b/143206389): Remove once we fully migrate to 3.X.\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(value\u001b[39m.\u001b[39m\u001b[39m__index__\u001b[39m())\n\u001b[1;32m    213\u001b[0m   \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    215\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mDimension value must be integer or None or have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    216\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39man __index__ method, got value \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{0!r}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m with type \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{1!r}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    217\u001b[0m             value, \u001b[39mtype\u001b[39m(value))) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "X_train, X_validation, X_test, y_train, y_validation, y_test = load_dataset(0.3, 0.2)\n",
    "print(X_train.shape)\n",
    "\n",
    "input_shape = (X_train[1], X_train[2], X_train[3])\n",
    "model = build_model(input_shape)\n",
    "\n",
    "optimazer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimazer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_validation, y_validation))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# evaluate model on test set\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m test_error, test_accuracy \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(X_test, y_test, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAccuracy on test set is: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(test_accuracy))\n\u001b[1;32m      5\u001b[0m \u001b[39m# plot accuracy/error for training and validation\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# evaluate model on test set\n",
    "test_error, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Accuracy on test set is: {}\".format(test_accuracy))\n",
    "\n",
    "# plot accuracy/error for training and validation\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[-3.94451538e+02]\n",
      "   [ 9.50516586e+01]\n",
      "   [ 6.77674103e+01]\n",
      "   ...\n",
      "   [ 6.12180328e+00]\n",
      "   [ 4.62497520e+00]\n",
      "   [ 3.09662485e+00]]\n",
      "\n",
      "  [[-3.15396667e+02]\n",
      "   [ 1.66267914e+02]\n",
      "   [ 7.30263519e+01]\n",
      "   ...\n",
      "   [ 3.85163093e+00]\n",
      "   [ 5.06497478e+00]\n",
      "   [ 3.18533087e+00]]\n",
      "\n",
      "  [[-3.00560974e+02]\n",
      "   [ 1.77877533e+02]\n",
      "   [ 7.02767944e+01]\n",
      "   ...\n",
      "   [ 6.01160240e+00]\n",
      "   [ 5.99095535e+00]\n",
      "   [ 4.07767105e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-4.70819519e+02]\n",
      "   [ 0.00000000e+00]\n",
      "   [ 0.00000000e+00]\n",
      "   ...\n",
      "   [ 0.00000000e+00]\n",
      "   [ 0.00000000e+00]\n",
      "   [ 0.00000000e+00]]\n",
      "\n",
      "  [[-4.70501190e+02]\n",
      "   [ 4.46713448e-01]\n",
      "   [ 4.36372697e-01]\n",
      "   ...\n",
      "   [-2.22656518e-01]\n",
      "   [-2.67100215e-01]\n",
      "   [-3.07194173e-01]]\n",
      "\n",
      "  [[-4.67021759e+02]\n",
      "   [ 5.30994987e+00]\n",
      "   [ 5.12979126e+00]\n",
      "   ...\n",
      "   [-1.19331145e+00]\n",
      "   [-1.25106215e+00]\n",
      "   [-1.25720203e+00]]]\n",
      "\n",
      "\n",
      " [[[-4.50180328e+02]\n",
      "   [ 6.64707489e+01]\n",
      "   [ 3.63920898e+01]\n",
      "   ...\n",
      "   [-8.48662317e-01]\n",
      "   [-3.64365458e+00]\n",
      "   [-3.05392480e+00]]\n",
      "\n",
      "  [[-4.26619263e+02]\n",
      "   [ 9.25543823e+01]\n",
      "   [ 4.77410774e+01]\n",
      "   ...\n",
      "   [ 2.18969226e-01]\n",
      "   [-1.82208288e+00]\n",
      "   [-1.69128871e+00]]\n",
      "\n",
      "  [[-3.93304535e+02]\n",
      "   [ 1.28791245e+02]\n",
      "   [ 6.61955261e+01]\n",
      "   ...\n",
      "   [ 6.05084276e+00]\n",
      "   [ 4.75201988e+00]\n",
      "   [ 9.99950886e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-4.28142456e+02]\n",
      "   [ 8.67424927e+01]\n",
      "   [ 3.67949715e+01]\n",
      "   ...\n",
      "   [-1.18791842e+00]\n",
      "   [-7.10003614e-01]\n",
      "   [ 8.18024874e-02]]\n",
      "\n",
      "  [[-4.28578186e+02]\n",
      "   [ 8.57944031e+01]\n",
      "   [ 3.50240440e+01]\n",
      "   ...\n",
      "   [ 6.56936467e-01]\n",
      "   [-1.19136751e+00]\n",
      "   [-1.88341379e+00]]\n",
      "\n",
      "  [[-4.46833008e+02]\n",
      "   [ 6.80579071e+01]\n",
      "   [ 3.23350220e+01]\n",
      "   ...\n",
      "   [ 6.99605703e+00]\n",
      "   [ 3.10706544e+00]\n",
      "   [-6.21600509e-01]]]\n",
      "\n",
      "\n",
      " [[[-4.69534271e+02]\n",
      "   [ 5.59877319e+01]\n",
      "   [ 5.14954224e+01]\n",
      "   ...\n",
      "   [ 4.08318996e+00]\n",
      "   [ 4.36228180e+00]\n",
      "   [ 4.01900387e+00]]\n",
      "\n",
      "  [[-4.33763336e+02]\n",
      "   [ 9.87349854e+01]\n",
      "   [ 7.75805283e+01]\n",
      "   ...\n",
      "   [ 5.07730246e+00]\n",
      "   [ 6.33988667e+00]\n",
      "   [ 6.19224358e+00]]\n",
      "\n",
      "  [[-4.07135895e+02]\n",
      "   [ 1.26856926e+02]\n",
      "   [ 8.63670883e+01]\n",
      "   ...\n",
      "   [ 1.75488925e+00]\n",
      "   [ 2.99946070e+00]\n",
      "   [ 4.48057842e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-5.02929047e+02]\n",
      "   [ 1.02906132e+01]\n",
      "   [ 9.92015934e+00]\n",
      "   ...\n",
      "   [-2.12265825e+00]\n",
      "   [-2.17919159e+00]\n",
      "   [-2.15664577e+00]]\n",
      "\n",
      "  [[-4.97931335e+02]\n",
      "   [ 1.72312317e+01]\n",
      "   [ 1.64999809e+01]\n",
      "   ...\n",
      "   [-2.41737318e+00]\n",
      "   [-2.34398484e+00]\n",
      "   [-2.15263891e+00]]\n",
      "\n",
      "  [[-4.96642609e+02]\n",
      "   [ 1.90067978e+01]\n",
      "   [ 1.81310081e+01]\n",
      "   ...\n",
      "   [-2.82984829e+00]\n",
      "   [-2.42530680e+00]\n",
      "   [-1.92804086e+00]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[-4.36641968e+02]\n",
      "   [ 9.47186127e+01]\n",
      "   [ 7.30399399e+01]\n",
      "   ...\n",
      "   [ 3.57333899e+00]\n",
      "   [ 1.96828201e-01]\n",
      "   [-1.08254182e+00]]\n",
      "\n",
      "  [[-3.99756592e+02]\n",
      "   [ 1.30862213e+02]\n",
      "   [ 8.02145920e+01]\n",
      "   ...\n",
      "   [ 1.64536023e+00]\n",
      "   [ 1.85281798e-01]\n",
      "   [ 1.20908678e+00]]\n",
      "\n",
      "  [[-3.81436707e+02]\n",
      "   [ 1.39069443e+02]\n",
      "   [ 6.61332703e+01]\n",
      "   ...\n",
      "   [-3.83988523e+00]\n",
      "   [-4.21265304e-01]\n",
      "   [ 4.55038452e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-4.92197449e+02]\n",
      "   [ 2.44474716e+01]\n",
      "   [ 2.33103199e+01]\n",
      "   ...\n",
      "   [-3.87828970e+00]\n",
      "   [-3.62189102e+00]\n",
      "   [-3.04594111e+00]]\n",
      "\n",
      "  [[-4.90106201e+02]\n",
      "   [ 2.71384811e+01]\n",
      "   [ 2.54261189e+01]\n",
      "   ...\n",
      "   [-2.42962813e+00]\n",
      "   [-2.03742170e+00]\n",
      "   [-1.32621145e+00]]\n",
      "\n",
      "  [[-4.75156372e+02]\n",
      "   [ 4.63381615e+01]\n",
      "   [ 3.97674179e+01]\n",
      "   ...\n",
      "   [-3.53068888e-01]\n",
      "   [-1.18862844e+00]\n",
      "   [-1.75512254e+00]]]\n",
      "\n",
      "\n",
      " [[[-4.30009308e+02]\n",
      "   [ 5.01873665e+01]\n",
      "   [ 4.83094177e+01]\n",
      "   ...\n",
      "   [ 4.94190407e+00]\n",
      "   [ 5.20863771e+00]\n",
      "   [ 5.41571283e+00]]\n",
      "\n",
      "  [[-3.78475494e+02]\n",
      "   [ 1.02805252e+02]\n",
      "   [ 6.67997742e+01]\n",
      "   ...\n",
      "   [ 2.95981431e+00]\n",
      "   [ 5.30619431e+00]\n",
      "   [ 7.33827782e+00]]\n",
      "\n",
      "  [[-3.35326538e+02]\n",
      "   [ 1.35688889e+02]\n",
      "   [ 5.79009171e+01]\n",
      "   ...\n",
      "   [ 2.63514566e+00]\n",
      "   [ 7.79232216e+00]\n",
      "   [ 9.30283546e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-4.51926971e+02]\n",
      "   [ 1.96509972e+01]\n",
      "   [ 1.91176987e+01]\n",
      "   ...\n",
      "   [-4.31794524e-01]\n",
      "   [-6.77924275e-01]\n",
      "   [-7.67825007e-01]]\n",
      "\n",
      "  [[-4.48425659e+02]\n",
      "   [ 2.44403095e+01]\n",
      "   [ 2.34340973e+01]\n",
      "   ...\n",
      "   [-6.08460069e-01]\n",
      "   [-2.97978520e-01]\n",
      "   [ 4.22369540e-02]]\n",
      "\n",
      "  [[-4.46173401e+02]\n",
      "   [ 2.75143852e+01]\n",
      "   [ 2.61873550e+01]\n",
      "   ...\n",
      "   [ 6.20514095e-01]\n",
      "   [ 1.03312445e+00]\n",
      "   [ 1.34199739e+00]]]\n",
      "\n",
      "\n",
      " [[[-4.55605499e+02]\n",
      "   [ 8.08627930e+01]\n",
      "   [ 6.72358704e+01]\n",
      "   ...\n",
      "   [ 5.49779534e-01]\n",
      "   [ 1.81748414e+00]\n",
      "   [ 5.00288391e+00]]\n",
      "\n",
      "  [[-4.05419312e+02]\n",
      "   [ 1.27193954e+02]\n",
      "   [ 7.12811890e+01]\n",
      "   ...\n",
      "   [-2.82333374e+00]\n",
      "   [-5.37394166e-01]\n",
      "   [ 5.92457581e+00]]\n",
      "\n",
      "  [[-3.87010345e+02]\n",
      "   [ 1.42508636e+02]\n",
      "   [ 7.14266510e+01]\n",
      "   ...\n",
      "   [-2.90885115e+00]\n",
      "   [-1.77903724e+00]\n",
      "   [ 3.89344883e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-4.93537048e+02]\n",
      "   [ 3.29168243e+01]\n",
      "   [ 3.08693962e+01]\n",
      "   ...\n",
      "   [-2.37006044e+00]\n",
      "   [-1.49028707e+00]\n",
      "   [-2.78018534e-01]]\n",
      "\n",
      "  [[-4.92920929e+02]\n",
      "   [ 3.38857613e+01]\n",
      "   [ 3.18810329e+01]\n",
      "   ...\n",
      "   [-2.53384519e+00]\n",
      "   [-1.12660420e+00]\n",
      "   [ 2.15127990e-01]]\n",
      "\n",
      "  [[-4.89654083e+02]\n",
      "   [ 3.83783722e+01]\n",
      "   [ 3.60220490e+01]\n",
      "   ...\n",
      "   [-3.34937906e+00]\n",
      "   [-1.76773739e+00]\n",
      "   [-2.94086039e-01]]]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 106ms/step\n",
      "Expected index: 1, Predicted index: [1]\n"
     ]
    }
   ],
   "source": [
    "# test model\n",
    "X = X_test[5]\n",
    "y = y_test[5]\n",
    "\n",
    "prediction = model.predict(X[np.newaxis, ...])\n",
    "predicted_index = np.argmax(prediction, axis=1)\n",
    "\n",
    "print(\"Expected index: {}, Predicted index: {}\".format(y, predicted_index))\n",
    "\n",
    "# save model\n",
    "model.save(\"model_mfcc.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/mamet/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"/home/mamet/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/mamet/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/home/mamet/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"/home/mamet/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/mamet/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 130, 20, 1), found shape=(None, 96, 20)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m mfcc \u001b[39m=\u001b[39m mfcc[np\u001b[39m.\u001b[39mnewaxis, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m]\n\u001b[1;32m     15\u001b[0m \u001b[39m# get the predicted label\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(mfcc)\n\u001b[1;32m     17\u001b[0m predicted_index \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(predictions, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mPredicted keyword is: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(predicted_index))\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file5itcspg2.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/mamet/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"/home/mamet/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/mamet/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/home/mamet/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"/home/mamet/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/mamet/anaconda3/envs/tf/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 130, 20, 1), found shape=(None, 96, 20)\n"
     ]
    }
   ],
   "source": [
    "# test with real data\n",
    "audio = \"data/training/MR/New_MR_103.wav\"\n",
    "signal, sr = librosa.load(audio)\n",
    "\n",
    "# extract MFCCs\n",
    "mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=20, n_fft=2048, hop_length=512, n_mels=128)\n",
    "mfcc = mfcc.T\n",
    "\n",
    "# load model\n",
    "model = tf.keras.models.load_model(\"model_mfcc.h5\")\n",
    "\n",
    "# add an axis to input data for sample\n",
    "mfcc = mfcc[np.newaxis, ...]\n",
    "\n",
    "# get the predicted label\n",
    "predictions = model.predict(mfcc)\n",
    "predicted_index = np.argmax(predictions, axis=1)\n",
    "\n",
    "print(\"Predicted keyword is: {}\".format(predicted_index))\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
